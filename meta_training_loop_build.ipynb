{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd05807788318072d650ff7d3f12118168354b5d5c1b01788c0f8c7e03b8ca64544",
   "display_name": "Python 3.8.8 64-bit ('acts': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy \n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, get_constant_schedule_with_warmup\n",
    "\n",
    "from models.seqtransformer import SeqTransformer\n",
    "from data.unified_emotion import unified_emotion\n",
    "from data.utils.sampling import dataset_sampler\n",
    "from data.utils.tokenizer import manual_tokenizer\n",
    "from utils.metrics import logging_metrics\n",
    "\n",
    "###############################################\n",
    "### HANDLE WITH ARGPARSER #####################\n",
    "###############################################\n",
    "\n",
    "###\n",
    "### Model definition hyperparameters \n",
    "###\n",
    "# Pre-trained model name (from Huggingface)\n",
    "#bert_name = 'bert-base-uncased'\n",
    "encoder_name = 'vinai/bertweet-base'\n",
    "# Max to layer keep frozen. 11 keeps model frozen, -1 makes BERT totally trainable\n",
    "nu = 10\n",
    "\n",
    "# MLP hidden layers\n",
    "hidden_dims = [512, 256]\n",
    "# Which activation to use. Currently either tanh or ReLU\n",
    "act_fn = 'tanh'\n",
    "\n",
    "# Emulate config file\n",
    "config = {'encoder_name': encoder_name, \n",
    "'nu': nu,\n",
    "'hidden_dims': hidden_dims,\n",
    "'act_fn': act_fn\n",
    "}\n",
    "\n",
    "###\n",
    "### Meta-training definition hyper parameters \n",
    "###\n",
    "k = 4 # Number of shots\n",
    "n_inner = 7 # Number of inner loop updates\n",
    "n_outer = 1 # Number of outer loop updates before meta update\n",
    "n_episodes = 100\n",
    "\n",
    "###\n",
    "### Optimizer hyper parameters \n",
    "###\n",
    "meta_lr = 1e-3\n",
    "inner_lr = 1e-3\n",
    "output_lr = 1e-3\n",
    "warm_up_steps = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Training only on grounded_emotions\n",
    "excluded_tasks = ['dailydialog', 'crowdflower', 'tales-emotion', 'tec', 'emoint', 'fb-valence-arousal-anon', 'emobank', 'affectivetext', 'emotion-cause', 'electoraltweets', 'ssec', 'tales-emotions']\n",
    "\n",
    "dataset = unified_emotion(\"./data/datasets/unified-dataset.jsonl\", exclude=excluded_tasks)\n",
    "dataset.prep(text_tokenizer=manual_tokenizer)\n",
    "\n",
    "# Initialization and all that jazz\n",
    "\n",
    "model = SeqTransformer(config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(encoder_name)\n",
    "\n",
    "shared_optimizer = optim.SGD(model.parameters(), lr=meta_lr)\n",
    "shared_lr_schedule = get_constant_schedule_with_warmup(shared_optimizer, warm_up_steps)\n",
    "\n",
    "lossfn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SeqTransformer(\n  (encoder): TransformerEncoder(\n    (model): RobertaModel(\n      (embeddings): RobertaEmbeddings(\n        (word_embeddings): Embedding(64001, 768, padding_idx=1)\n        (position_embeddings): Embedding(130, 768, padding_idx=1)\n        (token_type_embeddings): Embedding(1, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (encoder): RobertaEncoder(\n        (layer): ModuleList(\n          (0): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (1): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (2): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (3): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (4): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (5): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (6): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (7): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (8): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (9): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (10): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (11): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (pooler): RobertaPooler(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (activation): Tanh()\n      )\n    )\n  )\n  (mlp): MLP(\n    (mlp): Sequential(\n      (0): Linear(in_features=768, out_features=512, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=512, out_features=256, bias=True)\n      (3): Tanh()\n    )\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " , N=2 | Loss 6.9099E-01, Acc 75.00, F1 73.33\n",
      "Episode 55 finished.\n",
      "\n",
      "Episode 56 | Task 1/1, inner 0 | Loss 6.7893E-01\n",
      "Episode 56 | Task 1/1, inner 1 | Loss 6.8359E-01\n",
      "Episode 56 | Task 1/1, inner 2 | Loss 6.8054E-01\n",
      "Episode 56 | Task 1/1, inner 3 | Loss 6.8167E-01\n",
      "Episode 56 | Task 1/1, inner 4 | Loss 6.8424E-01\n",
      "Episode 56 | Task 1/1, inner 5 | Loss 6.8238E-01\n",
      "Episode 56 | Task 1/1, inner 6 | Loss 6.8242E-01\n",
      "Episode 56 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9180E-01, Acc 62.50, F1 56.36\n",
      "Episode 56 finished.\n",
      "\n",
      "Episode 57 | Task 1/1, inner 0 | Loss 6.8721E-01\n",
      "Episode 57 | Task 1/1, inner 1 | Loss 6.8468E-01\n",
      "Episode 57 | Task 1/1, inner 2 | Loss 6.8599E-01\n",
      "Episode 57 | Task 1/1, inner 3 | Loss 6.8688E-01\n",
      "Episode 57 | Task 1/1, inner 4 | Loss 6.8759E-01\n",
      "Episode 57 | Task 1/1, inner 5 | Loss 6.8682E-01\n",
      "Episode 57 | Task 1/1, inner 6 | Loss 6.8621E-01\n",
      "Episode 57 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9288E-01, Acc 62.50, F1 61.90\n",
      "Episode 57 finished.\n",
      "\n",
      "Episode 58 | Task 1/1, inner 0 | Loss 6.7268E-01\n",
      "Episode 58 | Task 1/1, inner 1 | Loss 6.6895E-01\n",
      "Episode 58 | Task 1/1, inner 2 | Loss 6.7321E-01\n",
      "Episode 58 | Task 1/1, inner 3 | Loss 6.6328E-01\n",
      "Episode 58 | Task 1/1, inner 4 | Loss 6.5848E-01\n",
      "Episode 58 | Task 1/1, inner 5 | Loss 6.7004E-01\n",
      "Episode 58 | Task 1/1, inner 6 | Loss 6.6554E-01\n",
      "Episode 58 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9401E-01, Acc 50.00, F1 33.33\n",
      "Episode 58 finished.\n",
      "\n",
      "Episode 59 | Task 1/1, inner 0 | Loss 6.7582E-01\n",
      "Episode 59 | Task 1/1, inner 1 | Loss 6.8875E-01\n",
      "Episode 59 | Task 1/1, inner 2 | Loss 6.6544E-01\n",
      "Episode 59 | Task 1/1, inner 3 | Loss 6.5894E-01\n",
      "Episode 59 | Task 1/1, inner 4 | Loss 6.7672E-01\n",
      "Episode 59 | Task 1/1, inner 5 | Loss 6.8246E-01\n",
      "Episode 59 | Task 1/1, inner 6 | Loss 6.8172E-01\n",
      "Episode 59 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9273E-01, Acc 50.00, F1 33.33\n",
      "Episode 59 finished.\n",
      "\n",
      "Episode 60 | Task 1/1, inner 0 | Loss 6.8288E-01\n",
      "Episode 60 | Task 1/1, inner 1 | Loss 6.8569E-01\n",
      "Episode 60 | Task 1/1, inner 2 | Loss 6.8768E-01\n",
      "Episode 60 | Task 1/1, inner 3 | Loss 6.8819E-01\n",
      "Episode 60 | Task 1/1, inner 4 | Loss 6.8833E-01\n",
      "Episode 60 | Task 1/1, inner 5 | Loss 6.9007E-01\n",
      "Episode 60 | Task 1/1, inner 6 | Loss 6.8500E-01\n",
      "Episode 60 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9390E-01, Acc 50.00, F1 33.33\n",
      "Episode 60 finished.\n",
      "\n",
      "Episode 61 | Task 1/1, inner 0 | Loss 6.8129E-01\n",
      "Episode 61 | Task 1/1, inner 1 | Loss 6.7736E-01\n",
      "Episode 61 | Task 1/1, inner 2 | Loss 6.8169E-01\n",
      "Episode 61 | Task 1/1, inner 3 | Loss 6.8027E-01\n",
      "Episode 61 | Task 1/1, inner 4 | Loss 6.7855E-01\n",
      "Episode 61 | Task 1/1, inner 5 | Loss 6.7889E-01\n",
      "Episode 61 | Task 1/1, inner 6 | Loss 6.8088E-01\n",
      "Episode 61 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9182E-01, Acc 62.50, F1 56.36\n",
      "Episode 61 finished.\n",
      "\n",
      "Episode 62 | Task 1/1, inner 0 | Loss 6.7709E-01\n",
      "Episode 62 | Task 1/1, inner 1 | Loss 6.7945E-01\n",
      "Episode 62 | Task 1/1, inner 2 | Loss 6.7717E-01\n",
      "Episode 62 | Task 1/1, inner 3 | Loss 6.8617E-01\n",
      "Episode 62 | Task 1/1, inner 4 | Loss 6.7831E-01\n",
      "Episode 62 | Task 1/1, inner 5 | Loss 6.8080E-01\n",
      "Episode 62 | Task 1/1, inner 6 | Loss 6.8374E-01\n",
      "Episode 62 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8670E-01, Acc 87.50, F1 87.30\n",
      "Episode 62 finished.\n",
      "\n",
      "Episode 63 | Task 1/1, inner 0 | Loss 6.8116E-01\n",
      "Episode 63 | Task 1/1, inner 1 | Loss 6.7869E-01\n",
      "Episode 63 | Task 1/1, inner 2 | Loss 6.8150E-01\n",
      "Episode 63 | Task 1/1, inner 3 | Loss 6.8438E-01\n",
      "Episode 63 | Task 1/1, inner 4 | Loss 6.7837E-01\n",
      "Episode 63 | Task 1/1, inner 5 | Loss 6.7700E-01\n",
      "Episode 63 | Task 1/1, inner 6 | Loss 6.7804E-01\n",
      "Episode 63 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9210E-01, Acc 50.00, F1 46.67\n",
      "Episode 63 finished.\n",
      "\n",
      "Episode 64 | Task 1/1, inner 0 | Loss 6.7872E-01\n",
      "Episode 64 | Task 1/1, inner 1 | Loss 6.8290E-01\n",
      "Episode 64 | Task 1/1, inner 2 | Loss 6.8296E-01\n",
      "Episode 64 | Task 1/1, inner 3 | Loss 6.7913E-01\n",
      "Episode 64 | Task 1/1, inner 4 | Loss 6.8078E-01\n",
      "Episode 64 | Task 1/1, inner 5 | Loss 6.8027E-01\n",
      "Episode 64 | Task 1/1, inner 6 | Loss 6.8331E-01\n",
      "Episode 64 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9136E-01, Acc 50.00, F1 33.33\n",
      "Episode 64 finished.\n",
      "\n",
      "Episode 65 | Task 1/1, inner 0 | Loss 6.8463E-01\n",
      "Episode 65 | Task 1/1, inner 1 | Loss 6.8139E-01\n",
      "Episode 65 | Task 1/1, inner 2 | Loss 6.7942E-01\n",
      "Episode 65 | Task 1/1, inner 3 | Loss 6.7959E-01\n",
      "Episode 65 | Task 1/1, inner 4 | Loss 6.8359E-01\n",
      "Episode 65 | Task 1/1, inner 5 | Loss 6.7949E-01\n",
      "Episode 65 | Task 1/1, inner 6 | Loss 6.8474E-01\n",
      "Episode 65 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9345E-01, Acc 50.00, F1 50.00\n",
      "Episode 65 finished.\n",
      "\n",
      "Episode 66 | Task 1/1, inner 0 | Loss 6.8233E-01\n",
      "Episode 66 | Task 1/1, inner 1 | Loss 6.8540E-01\n",
      "Episode 66 | Task 1/1, inner 2 | Loss 6.8114E-01\n",
      "Episode 66 | Task 1/1, inner 3 | Loss 6.8215E-01\n",
      "Episode 66 | Task 1/1, inner 4 | Loss 6.8494E-01\n",
      "Episode 66 | Task 1/1, inner 5 | Loss 6.8265E-01\n",
      "Episode 66 | Task 1/1, inner 6 | Loss 6.7953E-01\n",
      "Episode 66 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9084E-01, Acc 62.50, F1 61.90\n",
      "Episode 66 finished.\n",
      "\n",
      "Episode 67 | Task 1/1, inner 0 | Loss 6.8352E-01\n",
      "Episode 67 | Task 1/1, inner 1 | Loss 6.8198E-01\n",
      "Episode 67 | Task 1/1, inner 2 | Loss 6.8261E-01\n",
      "Episode 67 | Task 1/1, inner 3 | Loss 6.8075E-01\n",
      "Episode 67 | Task 1/1, inner 4 | Loss 6.8034E-01\n",
      "Episode 67 | Task 1/1, inner 5 | Loss 6.8477E-01\n",
      "Episode 67 | Task 1/1, inner 6 | Loss 6.8154E-01\n",
      "Episode 67 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9295E-01, Acc 37.50, F1 36.51\n",
      "Episode 67 finished.\n",
      "\n",
      "Episode 68 | Task 1/1, inner 0 | Loss 6.8067E-01\n",
      "Episode 68 | Task 1/1, inner 1 | Loss 6.7983E-01\n",
      "Episode 68 | Task 1/1, inner 2 | Loss 6.8383E-01\n",
      "Episode 68 | Task 1/1, inner 3 | Loss 6.8181E-01\n",
      "Episode 68 | Task 1/1, inner 4 | Loss 6.7717E-01\n",
      "Episode 68 | Task 1/1, inner 5 | Loss 6.8046E-01\n",
      "Episode 68 | Task 1/1, inner 6 | Loss 6.8170E-01\n",
      "Episode 68 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9139E-01, Acc 50.00, F1 50.00\n",
      "Episode 68 finished.\n",
      "\n",
      "Episode 69 | Task 1/1, inner 0 | Loss 6.8112E-01\n",
      "Episode 69 | Task 1/1, inner 1 | Loss 6.8185E-01\n",
      "Episode 69 | Task 1/1, inner 2 | Loss 6.8625E-01\n",
      "Episode 69 | Task 1/1, inner 3 | Loss 6.7980E-01\n",
      "Episode 69 | Task 1/1, inner 4 | Loss 6.8346E-01\n",
      "Episode 69 | Task 1/1, inner 5 | Loss 6.7983E-01\n",
      "Episode 69 | Task 1/1, inner 6 | Loss 6.8255E-01\n",
      "Episode 69 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9316E-01, Acc 50.00, F1 46.67\n",
      "Episode 69 finished.\n",
      "\n",
      "Episode 70 | Task 1/1, inner 0 | Loss 6.7945E-01\n",
      "Episode 70 | Task 1/1, inner 1 | Loss 6.8106E-01\n",
      "Episode 70 | Task 1/1, inner 2 | Loss 6.7589E-01\n",
      "Episode 70 | Task 1/1, inner 3 | Loss 6.7848E-01\n",
      "Episode 70 | Task 1/1, inner 4 | Loss 6.8299E-01\n",
      "Episode 70 | Task 1/1, inner 5 | Loss 6.7976E-01\n",
      "Episode 70 | Task 1/1, inner 6 | Loss 6.8253E-01\n",
      "Episode 70 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9417E-01, Acc 37.50, F1 27.27\n",
      "Episode 70 finished.\n",
      "\n",
      "Episode 71 | Task 1/1, inner 0 | Loss 6.7779E-01\n",
      "Episode 71 | Task 1/1, inner 1 | Loss 6.8042E-01\n",
      "Episode 71 | Task 1/1, inner 2 | Loss 6.8189E-01\n",
      "Episode 71 | Task 1/1, inner 3 | Loss 6.7901E-01\n",
      "Episode 71 | Task 1/1, inner 4 | Loss 6.8000E-01\n",
      "Episode 71 | Task 1/1, inner 5 | Loss 6.8253E-01\n",
      "Episode 71 | Task 1/1, inner 6 | Loss 6.8440E-01\n",
      "Episode 71 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8965E-01, Acc 62.50, F1 61.90\n",
      "Episode 71 finished.\n",
      "\n",
      "Episode 72 | Task 1/1, inner 0 | Loss 6.7305E-01\n",
      "Episode 72 | Task 1/1, inner 1 | Loss 6.7754E-01\n",
      "Episode 72 | Task 1/1, inner 2 | Loss 6.6568E-01\n",
      "Episode 72 | Task 1/1, inner 3 | Loss 6.7415E-01\n",
      "Episode 72 | Task 1/1, inner 4 | Loss 6.7277E-01\n",
      "Episode 72 | Task 1/1, inner 5 | Loss 6.6933E-01\n",
      "Episode 72 | Task 1/1, inner 6 | Loss 6.7674E-01\n",
      "Episode 72 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9765E-01, Acc 50.00, F1 46.67\n",
      "Episode 72 finished.\n",
      "\n",
      "Episode 73 | Task 1/1, inner 0 | Loss 6.8108E-01\n",
      "Episode 73 | Task 1/1, inner 1 | Loss 6.8135E-01\n",
      "Episode 73 | Task 1/1, inner 2 | Loss 6.8009E-01\n",
      "Episode 73 | Task 1/1, inner 3 | Loss 6.8236E-01\n",
      "Episode 73 | Task 1/1, inner 4 | Loss 6.8070E-01\n",
      "Episode 73 | Task 1/1, inner 5 | Loss 6.8821E-01\n",
      "Episode 73 | Task 1/1, inner 6 | Loss 6.7703E-01\n",
      "Episode 73 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9230E-01, Acc 50.00, F1 50.00\n",
      "Episode 73 finished.\n",
      "\n",
      "Episode 74 | Task 1/1, inner 0 | Loss 6.8527E-01\n",
      "Episode 74 | Task 1/1, inner 1 | Loss 6.8322E-01\n",
      "Episode 74 | Task 1/1, inner 2 | Loss 6.8329E-01\n",
      "Episode 74 | Task 1/1, inner 3 | Loss 6.8320E-01\n",
      "Episode 74 | Task 1/1, inner 4 | Loss 6.8796E-01\n",
      "Episode 74 | Task 1/1, inner 5 | Loss 6.8241E-01\n",
      "Episode 74 | Task 1/1, inner 6 | Loss 6.8010E-01\n",
      "Episode 74 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9680E-01, Acc 37.50, F1 27.27\n",
      "Episode 74 finished.\n",
      "\n",
      "Episode 75 | Task 1/1, inner 0 | Loss 6.7879E-01\n",
      "Episode 75 | Task 1/1, inner 1 | Loss 6.8147E-01\n",
      "Episode 75 | Task 1/1, inner 2 | Loss 6.7807E-01\n",
      "Episode 75 | Task 1/1, inner 3 | Loss 6.7854E-01\n",
      "Episode 75 | Task 1/1, inner 4 | Loss 6.7775E-01\n",
      "Episode 75 | Task 1/1, inner 5 | Loss 6.7856E-01\n",
      "Episode 75 | Task 1/1, inner 6 | Loss 6.8137E-01\n",
      "Episode 75 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9399E-01, Acc 50.00, F1 46.67\n",
      "Episode 75 finished.\n",
      "\n",
      "Episode 76 | Task 1/1, inner 0 | Loss 6.8080E-01\n",
      "Episode 76 | Task 1/1, inner 1 | Loss 6.7951E-01\n",
      "Episode 76 | Task 1/1, inner 2 | Loss 6.7661E-01\n",
      "Episode 76 | Task 1/1, inner 3 | Loss 6.8205E-01\n",
      "Episode 76 | Task 1/1, inner 4 | Loss 6.8331E-01\n",
      "Episode 76 | Task 1/1, inner 5 | Loss 6.8409E-01\n",
      "Episode 76 | Task 1/1, inner 6 | Loss 6.8105E-01\n",
      "Episode 76 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9004E-01, Acc 50.00, F1 33.33\n",
      "Episode 76 finished.\n",
      "\n",
      "Episode 77 | Task 1/1, inner 0 | Loss 6.8390E-01\n",
      "Episode 77 | Task 1/1, inner 1 | Loss 6.8354E-01\n",
      "Episode 77 | Task 1/1, inner 2 | Loss 6.8287E-01\n",
      "Episode 77 | Task 1/1, inner 3 | Loss 6.8060E-01\n",
      "Episode 77 | Task 1/1, inner 4 | Loss 6.8014E-01\n",
      "Episode 77 | Task 1/1, inner 5 | Loss 6.7847E-01\n",
      "Episode 77 | Task 1/1, inner 6 | Loss 6.7752E-01\n",
      "Episode 77 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9186E-01, Acc 62.50, F1 61.90\n",
      "Episode 77 finished.\n",
      "\n",
      "Episode 78 | Task 1/1, inner 0 | Loss 6.7850E-01\n",
      "Episode 78 | Task 1/1, inner 1 | Loss 6.7576E-01\n",
      "Episode 78 | Task 1/1, inner 2 | Loss 6.7881E-01\n",
      "Episode 78 | Task 1/1, inner 3 | Loss 6.7714E-01\n",
      "Episode 78 | Task 1/1, inner 4 | Loss 6.7893E-01\n",
      "Episode 78 | Task 1/1, inner 5 | Loss 6.7787E-01\n",
      "Episode 78 | Task 1/1, inner 6 | Loss 6.8699E-01\n",
      "Episode 78 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9211E-01, Acc 50.00, F1 33.33\n",
      "Episode 78 finished.\n",
      "\n",
      "Episode 79 | Task 1/1, inner 0 | Loss 6.7586E-01\n",
      "Episode 79 | Task 1/1, inner 1 | Loss 6.7811E-01\n",
      "Episode 79 | Task 1/1, inner 2 | Loss 6.7795E-01\n",
      "Episode 79 | Task 1/1, inner 3 | Loss 6.7526E-01\n",
      "Episode 79 | Task 1/1, inner 4 | Loss 6.7673E-01\n",
      "Episode 79 | Task 1/1, inner 5 | Loss 6.7448E-01\n",
      "Episode 79 | Task 1/1, inner 6 | Loss 6.7399E-01\n",
      "Episode 79 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8959E-01, Acc 62.50, F1 56.36\n",
      "Episode 79 finished.\n",
      "\n",
      "Episode 80 | Task 1/1, inner 0 | Loss 6.8217E-01\n",
      "Episode 80 | Task 1/1, inner 1 | Loss 6.8487E-01\n",
      "Episode 80 | Task 1/1, inner 2 | Loss 6.8324E-01\n",
      "Episode 80 | Task 1/1, inner 3 | Loss 6.8501E-01\n",
      "Episode 80 | Task 1/1, inner 4 | Loss 6.8642E-01\n",
      "Episode 80 | Task 1/1, inner 5 | Loss 6.8724E-01\n",
      "Episode 80 | Task 1/1, inner 6 | Loss 6.8485E-01\n",
      "Episode 80 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9293E-01, Acc 50.00, F1 33.33\n",
      "Episode 80 finished.\n",
      "\n",
      "Episode 81 | Task 1/1, inner 0 | Loss 6.7581E-01\n",
      "Episode 81 | Task 1/1, inner 1 | Loss 6.7260E-01\n",
      "Episode 81 | Task 1/1, inner 2 | Loss 6.8084E-01\n",
      "Episode 81 | Task 1/1, inner 3 | Loss 6.7805E-01\n",
      "Episode 81 | Task 1/1, inner 4 | Loss 6.7745E-01\n",
      "Episode 81 | Task 1/1, inner 5 | Loss 6.7739E-01\n",
      "Episode 81 | Task 1/1, inner 6 | Loss 6.7635E-01\n",
      "Episode 81 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9013E-01, Acc 87.50, F1 87.30\n",
      "Episode 81 finished.\n",
      "\n",
      "Episode 82 | Task 1/1, inner 0 | Loss 6.7737E-01\n",
      "Episode 82 | Task 1/1, inner 1 | Loss 6.7929E-01\n",
      "Episode 82 | Task 1/1, inner 2 | Loss 6.7704E-01\n",
      "Episode 82 | Task 1/1, inner 3 | Loss 6.7853E-01\n",
      "Episode 82 | Task 1/1, inner 4 | Loss 6.7735E-01\n",
      "Episode 82 | Task 1/1, inner 5 | Loss 6.8464E-01\n",
      "Episode 82 | Task 1/1, inner 6 | Loss 6.8035E-01\n",
      "Episode 82 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9438E-01, Acc 37.50, F1 36.51\n",
      "Episode 82 finished.\n",
      "\n",
      "Episode 83 | Task 1/1, inner 0 | Loss 6.8463E-01\n",
      "Episode 83 | Task 1/1, inner 1 | Loss 6.8455E-01\n",
      "Episode 83 | Task 1/1, inner 2 | Loss 6.8088E-01\n",
      "Episode 83 | Task 1/1, inner 3 | Loss 6.8238E-01\n",
      "Episode 83 | Task 1/1, inner 4 | Loss 6.8313E-01\n",
      "Episode 83 | Task 1/1, inner 5 | Loss 6.8307E-01\n",
      "Episode 83 | Task 1/1, inner 6 | Loss 6.8424E-01\n",
      "Episode 83 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9347E-01, Acc 37.50, F1 36.51\n",
      "Episode 83 finished.\n",
      "\n",
      "Episode 84 | Task 1/1, inner 0 | Loss 6.8634E-01\n",
      "Episode 84 | Task 1/1, inner 1 | Loss 6.8049E-01\n",
      "Episode 84 | Task 1/1, inner 2 | Loss 6.8264E-01\n",
      "Episode 84 | Task 1/1, inner 3 | Loss 6.8050E-01\n",
      "Episode 84 | Task 1/1, inner 4 | Loss 6.8439E-01\n",
      "Episode 84 | Task 1/1, inner 5 | Loss 6.8232E-01\n",
      "Episode 84 | Task 1/1, inner 6 | Loss 6.8641E-01\n",
      "Episode 84 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9220E-01, Acc 62.50, F1 61.90\n",
      "Episode 84 finished.\n",
      "\n",
      "Episode 85 | Task 1/1, inner 0 | Loss 6.7645E-01\n",
      "Episode 85 | Task 1/1, inner 1 | Loss 6.7594E-01\n",
      "Episode 85 | Task 1/1, inner 2 | Loss 6.7721E-01\n",
      "Episode 85 | Task 1/1, inner 3 | Loss 6.7978E-01\n",
      "Episode 85 | Task 1/1, inner 4 | Loss 6.8219E-01\n",
      "Episode 85 | Task 1/1, inner 5 | Loss 6.8105E-01\n",
      "Episode 85 | Task 1/1, inner 6 | Loss 6.8013E-01\n",
      "Episode 85 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9415E-01, Acc 37.50, F1 27.27\n",
      "Episode 85 finished.\n",
      "\n",
      "Episode 86 | Task 1/1, inner 0 | Loss 6.7496E-01\n",
      "Episode 86 | Task 1/1, inner 1 | Loss 6.8320E-01\n",
      "Episode 86 | Task 1/1, inner 2 | Loss 6.7842E-01\n",
      "Episode 86 | Task 1/1, inner 3 | Loss 6.7949E-01\n",
      "Episode 86 | Task 1/1, inner 4 | Loss 6.7986E-01\n",
      "Episode 86 | Task 1/1, inner 5 | Loss 6.8125E-01\n",
      "Episode 86 | Task 1/1, inner 6 | Loss 6.7984E-01\n",
      "Episode 86 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9228E-01, Acc 50.00, F1 46.67\n",
      "Episode 86 finished.\n",
      "\n",
      "Episode 87 | Task 1/1, inner 0 | Loss 6.8026E-01\n",
      "Episode 87 | Task 1/1, inner 1 | Loss 6.8068E-01\n",
      "Episode 87 | Task 1/1, inner 2 | Loss 6.8194E-01\n",
      "Episode 87 | Task 1/1, inner 3 | Loss 6.7699E-01\n",
      "Episode 87 | Task 1/1, inner 4 | Loss 6.8126E-01\n",
      "Episode 87 | Task 1/1, inner 5 | Loss 6.8083E-01\n",
      "Episode 87 | Task 1/1, inner 6 | Loss 6.8210E-01\n",
      "Episode 87 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9112E-01, Acc 50.00, F1 50.00\n",
      "Episode 87 finished.\n",
      "\n",
      "Episode 88 | Task 1/1, inner 0 | Loss 6.8322E-01\n",
      "Episode 88 | Task 1/1, inner 1 | Loss 6.8039E-01\n",
      "Episode 88 | Task 1/1, inner 2 | Loss 6.8038E-01\n",
      "Episode 88 | Task 1/1, inner 3 | Loss 6.8232E-01\n",
      "Episode 88 | Task 1/1, inner 4 | Loss 6.8543E-01\n",
      "Episode 88 | Task 1/1, inner 5 | Loss 6.8062E-01\n",
      "Episode 88 | Task 1/1, inner 6 | Loss 6.8267E-01\n",
      "Episode 88 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9701E-01, Acc 50.00, F1 33.33\n",
      "Episode 88 finished.\n",
      "\n",
      "Episode 89 | Task 1/1, inner 0 | Loss 6.8129E-01\n",
      "Episode 89 | Task 1/1, inner 1 | Loss 6.8501E-01\n",
      "Episode 89 | Task 1/1, inner 2 | Loss 6.8200E-01\n",
      "Episode 89 | Task 1/1, inner 3 | Loss 6.7906E-01\n",
      "Episode 89 | Task 1/1, inner 4 | Loss 6.8185E-01\n",
      "Episode 89 | Task 1/1, inner 5 | Loss 6.8135E-01\n",
      "Episode 89 | Task 1/1, inner 6 | Loss 6.7695E-01\n",
      "Episode 89 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9184E-01, Acc 50.00, F1 46.67\n",
      "Episode 89 finished.\n",
      "\n",
      "Episode 90 | Task 1/1, inner 0 | Loss 6.7760E-01\n",
      "Episode 90 | Task 1/1, inner 1 | Loss 6.7821E-01\n",
      "Episode 90 | Task 1/1, inner 2 | Loss 6.7825E-01\n",
      "Episode 90 | Task 1/1, inner 3 | Loss 6.8409E-01\n",
      "Episode 90 | Task 1/1, inner 4 | Loss 6.8058E-01\n",
      "Episode 90 | Task 1/1, inner 5 | Loss 6.8011E-01\n",
      "Episode 90 | Task 1/1, inner 6 | Loss 6.8024E-01\n",
      "Episode 90 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9163E-01, Acc 50.00, F1 46.67\n",
      "Episode 90 finished.\n",
      "\n",
      "Episode 91 | Task 1/1, inner 0 | Loss 6.8062E-01\n",
      "Episode 91 | Task 1/1, inner 1 | Loss 6.9163E-01\n",
      "Episode 91 | Task 1/1, inner 2 | Loss 6.8532E-01\n",
      "Episode 91 | Task 1/1, inner 3 | Loss 6.8219E-01\n",
      "Episode 91 | Task 1/1, inner 4 | Loss 6.7784E-01\n",
      "Episode 91 | Task 1/1, inner 5 | Loss 6.9038E-01\n",
      "Episode 91 | Task 1/1, inner 6 | Loss 6.8035E-01\n",
      "Episode 91 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9365E-01, Acc 50.00, F1 33.33\n",
      "Episode 91 finished.\n",
      "\n",
      "Episode 92 | Task 1/1, inner 0 | Loss 6.7264E-01\n",
      "Episode 92 | Task 1/1, inner 1 | Loss 6.6927E-01\n",
      "Episode 92 | Task 1/1, inner 2 | Loss 6.6663E-01\n",
      "Episode 92 | Task 1/1, inner 3 | Loss 6.7044E-01\n",
      "Episode 92 | Task 1/1, inner 4 | Loss 6.6789E-01\n",
      "Episode 92 | Task 1/1, inner 5 | Loss 6.6810E-01\n",
      "Episode 92 | Task 1/1, inner 6 | Loss 6.7325E-01\n",
      "Episode 92 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9655E-01, Acc 50.00, F1 33.33\n",
      "Episode 92 finished.\n",
      "\n",
      "Episode 93 | Task 1/1, inner 0 | Loss 6.8041E-01\n",
      "Episode 93 | Task 1/1, inner 1 | Loss 6.8196E-01\n",
      "Episode 93 | Task 1/1, inner 2 | Loss 6.8552E-01\n",
      "Episode 93 | Task 1/1, inner 3 | Loss 6.8412E-01\n",
      "Episode 93 | Task 1/1, inner 4 | Loss 6.8386E-01\n",
      "Episode 93 | Task 1/1, inner 5 | Loss 6.8461E-01\n",
      "Episode 93 | Task 1/1, inner 6 | Loss 6.7939E-01\n",
      "Episode 93 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9212E-01, Acc 50.00, F1 33.33\n",
      "Episode 93 finished.\n",
      "\n",
      "Episode 94 | Task 1/1, inner 0 | Loss 6.7835E-01\n",
      "Episode 94 | Task 1/1, inner 1 | Loss 6.7910E-01\n",
      "Episode 94 | Task 1/1, inner 2 | Loss 6.7541E-01\n",
      "Episode 94 | Task 1/1, inner 3 | Loss 6.7613E-01\n",
      "Episode 94 | Task 1/1, inner 4 | Loss 6.7661E-01\n",
      "Episode 94 | Task 1/1, inner 5 | Loss 6.8388E-01\n",
      "Episode 94 | Task 1/1, inner 6 | Loss 6.7862E-01\n",
      "Episode 94 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9040E-01, Acc 75.00, F1 73.33\n",
      "Episode 94 finished.\n",
      "\n",
      "Episode 95 | Task 1/1, inner 0 | Loss 6.8005E-01\n",
      "Episode 95 | Task 1/1, inner 1 | Loss 6.7910E-01\n",
      "Episode 95 | Task 1/1, inner 2 | Loss 6.7401E-01\n",
      "Episode 95 | Task 1/1, inner 3 | Loss 6.7795E-01\n",
      "Episode 95 | Task 1/1, inner 4 | Loss 6.7626E-01\n",
      "Episode 95 | Task 1/1, inner 5 | Loss 6.8165E-01\n",
      "Episode 95 | Task 1/1, inner 6 | Loss 6.7912E-01\n",
      "Episode 95 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9165E-01, Acc 37.50, F1 27.27\n",
      "Episode 95 finished.\n",
      "\n",
      "Episode 96 | Task 1/1, inner 0 | Loss 6.8433E-01\n",
      "Episode 96 | Task 1/1, inner 1 | Loss 6.8670E-01\n",
      "Episode 96 | Task 1/1, inner 2 | Loss 6.8598E-01\n",
      "Episode 96 | Task 1/1, inner 3 | Loss 6.8449E-01\n",
      "Episode 96 | Task 1/1, inner 4 | Loss 6.8546E-01\n",
      "Episode 96 | Task 1/1, inner 5 | Loss 6.8341E-01\n",
      "Episode 96 | Task 1/1, inner 6 | Loss 6.8315E-01\n",
      "Episode 96 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9100E-01, Acc 50.00, F1 33.33\n",
      "Episode 96 finished.\n",
      "\n",
      "Episode 97 | Task 1/1, inner 0 | Loss 6.8147E-01\n",
      "Episode 97 | Task 1/1, inner 1 | Loss 6.7828E-01\n",
      "Episode 97 | Task 1/1, inner 2 | Loss 6.8356E-01\n",
      "Episode 97 | Task 1/1, inner 3 | Loss 6.8107E-01\n",
      "Episode 97 | Task 1/1, inner 4 | Loss 6.7900E-01\n",
      "Episode 97 | Task 1/1, inner 5 | Loss 6.8136E-01\n",
      "Episode 97 | Task 1/1, inner 6 | Loss 6.8388E-01\n",
      "Episode 97 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9199E-01, Acc 50.00, F1 50.00\n",
      "Episode 97 finished.\n",
      "\n",
      "Episode 98 | Task 1/1, inner 0 | Loss 6.8756E-01\n",
      "Episode 98 | Task 1/1, inner 1 | Loss 6.7769E-01\n",
      "Episode 98 | Task 1/1, inner 2 | Loss 6.7803E-01\n",
      "Episode 98 | Task 1/1, inner 3 | Loss 6.8085E-01\n",
      "Episode 98 | Task 1/1, inner 4 | Loss 6.7847E-01\n",
      "Episode 98 | Task 1/1, inner 5 | Loss 6.7631E-01\n",
      "Episode 98 | Task 1/1, inner 6 | Loss 6.7988E-01\n",
      "Episode 98 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9769E-01, Acc 50.00, F1 33.33\n",
      "Episode 98 finished.\n",
      "\n",
      "Episode 99 | Task 1/1, inner 0 | Loss 6.8374E-01\n",
      "Episode 99 | Task 1/1, inner 1 | Loss 6.8072E-01\n",
      "Episode 99 | Task 1/1, inner 2 | Loss 6.8298E-01\n",
      "Episode 99 | Task 1/1, inner 3 | Loss 6.8054E-01\n",
      "Episode 99 | Task 1/1, inner 4 | Loss 6.8080E-01\n",
      "Episode 99 | Task 1/1, inner 5 | Loss 6.7957E-01\n",
      "Episode 99 | Task 1/1, inner 6 | Loss 6.8094E-01\n",
      "Episode 99 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9684E-01, Acc 25.00, F1 20.00\n",
      "Episode 99 finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source_name = dataset_sampler(dataset, sampling_method='sqrt')\n",
    "support_loader, query_loader = dataset.get_dataloader(source_name, k=k, tokenizer=tokenizer, shuffle=True)\n",
    "batch = next(support_loader)\n",
    "labels, text, attn_mask = batch\n",
    "\n",
    "query_batch = next(query_loader)\n",
    "q_labels, q_text, q_attn_mask = query_batch\n",
    "\n",
    "for i in range(n_episodes):\n",
    "    \n",
    "    for ii in range(n_outer):\n",
    "        \n",
    "        ##################\n",
    "        # Step 1         #\n",
    "        # Sample episode #\n",
    "        ################## \n",
    "        # Sample a dataset\n",
    "        source_name = dataset_sampler(dataset, sampling_method='sqrt')\n",
    "        support_loader, query_loader = dataset.get_dataloader(source_name, k=k, tokenizer=tokenizer, shuffle=True)\n",
    "\n",
    "        # Sample support set\n",
    "        batch = next(query_loader)\n",
    "        labels, text, attn_mask = batch\n",
    "\n",
    "        ########################\n",
    "        # Step 2               #\n",
    "        # Copy into task-model #\n",
    "        ######################## \n",
    "        # Copy shared model to task-specific model\n",
    "        model_task = deepcopy(model)\n",
    "\n",
    "        # Inner loop optimizer\n",
    "        task_optimizer = optim.SGD(model_task.parameters(), lr=inner_lr)    \n",
    "\n",
    "        #####################\n",
    "        # Step 3            #\n",
    "        # Prototype weights #\n",
    "        #####################        \n",
    "        # Embed with init_model\n",
    "        y = model(text, attn_mask)\n",
    "\n",
    "        # Generate initial classification weights and biases\n",
    "        prototypes = torch.stack([torch.mean(y[labels == i], dim=0) for i in dataset.label_map[source_name].values()])\n",
    "\n",
    "        W = 2 * prototypes\n",
    "        b = -torch.norm(prototypes, p=2, dim=1)\n",
    "\n",
    "        ######################\n",
    "        # Step 4             #\n",
    "        # Initialize out clf #\n",
    "        ###################### \n",
    "        # Separate graph\n",
    "        W_task, b_task = W.detach().clone(), b.detach().clone()\n",
    "        W_task.requires_grad, b_task.requires_grad = True, True\n",
    "\n",
    "        # Classifier optimizer\n",
    "        output_optimizer = optim.SGD([W_task, b_task], lr=output_lr)\n",
    "\n",
    "        ##############\n",
    "        # Step 5     #\n",
    "        # Inner loop #\n",
    "        ############## \n",
    "\n",
    "        model.train()\n",
    "        model_task.train()\n",
    "\n",
    "        for iii in range(n_inner):\n",
    "            # Load data\n",
    "            #batch = next(support_loader)\n",
    "            #labels, text, attn_mask = batch\n",
    "\n",
    "            # Embed, encode, classify and compute loss\n",
    "            y = model_task(text, attn_mask)\n",
    "            logits = F.linear(y, W_task, b_task)\n",
    "            loss = lossfn(logits, labels)\n",
    "\n",
    "            # Backprop the output parameters\n",
    "            # Retrain graph for shared parameters\n",
    "            W_task.grad, b_task.grad = torch.autograd.grad(loss, [W_task, b_task], retain_graph=True)\n",
    "\n",
    "            # Calculate the gradients on shared parameters here    \n",
    "            updateable_task_params = [param for param in model_task.parameters() if param.requires_grad]\n",
    "            task_grads = torch.autograd.grad(loss, updateable_task_params)\n",
    "\n",
    "            # Store task-specific gradients\n",
    "            for param, grad in zip(updateable_task_params, task_grads):\n",
    "                param.grad = grad\n",
    "            updateable_task_params = None\n",
    "\n",
    "            # Update the parameters\n",
    "            output_optimizer.step()\n",
    "            task_optimizer.step()\n",
    "\n",
    "            output_optimizer.zero_grad()\n",
    "            task_optimizer.zero_grad()\n",
    "\n",
    "            print(\"Episode {} | Task {}/{}, inner {} | Loss {:.4E}\".format(i, ii+1, n_outer, iii, loss.detach().item()))\n",
    "        \n",
    "        #############\n",
    "        # Step 6    #\n",
    "        # Re-attach #\n",
    "        ############# \n",
    "        W_task = 2 * prototypes + (W_task - 2 * prototypes).detach()\n",
    "        b_task = -torch.norm(prototypes, p=2, dim=1) + (b_task + torch.norm(prototypes, p=2, dim=1)).detach()\n",
    "\n",
    "        ########################\n",
    "        # Step 7               #\n",
    "        # Outer loop gradients #\n",
    "        ########################\n",
    "        model.eval()\n",
    "        model_task.eval()\n",
    "\n",
    "        # Load Query\n",
    "        #query_batch = next(query_loader)\n",
    "        #q_labels, q_text, q_attn_mask = query_batch\n",
    "\n",
    "        # Push data through task-specific model\n",
    "        y = model_task(q_text, q_attn_mask)\n",
    "        logits = F.linear(y, W_task, b_task)\n",
    "        loss = lossfn(logits, q_labels)\n",
    "\n",
    "        # Calculate gradients for task-specific parameters    \n",
    "        updateable_task_params = [param for param in model_task.parameters() if param.requires_grad]\n",
    "        task_grads = torch.autograd.grad(loss, updateable_task_params, retain_graph=True)\n",
    "        updateable_task_params = None\n",
    "\n",
    "        # Calculate gradients for shared model parameters    \n",
    "        updateable_model_params = [param for param in model.parameters() if param.requires_grad]\n",
    "        model_grads = torch.autograd.grad(loss, updateable_model_params)\n",
    "\n",
    "        ########################\n",
    "        # Step 8               #\n",
    "        # Accumulate gradients #\n",
    "        ######################## \n",
    "        for param, g_task, g_init in zip(updateable_model_params, task_grads, model_grads):\n",
    "            if param.grad == None:\n",
    "                param.grad = g_task + g_init\n",
    "            else:\n",
    "                param.grad += g_task + g_init\n",
    "        updateable_model_params = None\n",
    "\n",
    "        # TODO: add logging for outer loop updates here\n",
    "        n_classes = len(dataset.label_map[source_name].keys())\n",
    "        mets = logging_metrics(logits.detach().cpu(), labels.detach().cpu())\n",
    "        print(\"Episode {} | Task {}/{}: {:<20s}, N={} | Loss {:.4E}, Acc {:5.2f}, F1 {:5.2f}\".format(i, ii+1, n_outer, source_name, n_classes, loss.detach().item(), mets['acc']*100, mets['f1']*100))\n",
    "\n",
    "    print(\"Episode {} finished.\\n\".format(i))\n",
    "\n",
    "    #####################\n",
    "    # Step 9            #\n",
    "    # Outer loop update #\n",
    "    ##################### \n",
    "\n",
    "    shared_optimizer.step()\n",
    "    shared_lr_schedule.step()\n",
    "    \n",
    "    shared_optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6904201da632>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Embed, encode, classify and compute loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_task\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_task\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_task\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlossfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ivoon\\Documents\\GitHub\\meta-learning-emotion-detection\\models\\seqtransformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, text, attn_mask)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ivoon\\Documents\\GitHub\\meta-learning-emotion-detection\\modules\\encoders.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, text, attn_mask)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pooler_output'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    813\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m         )\n\u001b[1;32m--> 815\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m    816\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    506\u001b[0m                 )\n\u001b[0;32m    507\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    509\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[0;32m    396\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     ):\n\u001b[1;32m--> 323\u001b[1;33m         self_outputs = self.self(\n\u001b[0m\u001b[0;32m    324\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     ):\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mmixed_query_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;31m# If this is instantiated as a cross-attention module, the keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1753\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iii in range(n_inner):\n",
    "    # Load data\n",
    "    #batch = next(support_loader)\n",
    "    #labels, text, attn_mask = batch\n",
    "\n",
    "    # Embed, encode, classify and compute loss\n",
    "    y = model_task(text, attn_mask)\n",
    "    logits = F.linear(y, W_task, b_task)\n",
    "    loss = lossfn(logits, labels)\n",
    "\n",
    "    # Backprop the output parameters\n",
    "    # Retrain graph for shared parameters\n",
    "    W_task.grad, b_task.grad = torch.autograd.grad(loss, [W_task, b_task], retain_graph=True)\n",
    "\n",
    "    # Calculate the gradients on shared parameters here    \n",
    "    updateable_task_params = [param for param in model_task.parameters() if param.requires_grad]\n",
    "    task_grads = torch.autograd.grad(loss, updateable_task_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "The shape of the mask [2, 8] at index 0 does not match the shape of the indexed tensor [8, 1, 256] at index 0",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-a0a27774f348>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: The shape of the mask [2, 8] at index 0 does not match the shape of the indexed tensor [8, 1, 256] at index 0"
     ]
    }
   ],
   "source": [
    "y[labels == torch.unique(labels).unsqueeze(1)]"
   ]
  },
  {
   "source": [
    "# Class definitions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy \n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers import AutoTokenizer, get_constant_schedule_with_warmup\n",
    "\n",
    "from models.protomaml_seqtransformer import ProtoMAMLSeqTransformer\n",
    "from data.unified_emotion import unified_emotion\n",
    "from data.utils.sampling import dataset_sampler\n",
    "from data.utils.tokenizer import manual_tokenizer\n",
    "from utils.metrics import logging_metrics\n",
    "\n",
    "def meta_evaluate(model, dataset, tokenizer, config, k=16):\n",
    "    \"\"\"\n",
    "    Check model performance on all datasets.\n",
    "    DO NOT CALL with torch.no_grad(). THIS IS HANDLED INSIDE.\n",
    "\n",
    "    Args:\n",
    "        model: model currently being trained\n",
    "        dataset: current dataset\n",
    "        tokenizer (AutoTokenizer): Huggingface's tokenizer to match the model\n",
    "        config (dict): training config dictionary\n",
    "        k (int, optional): size of the k-shot. Defaults to 16.\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary with metrics per task\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    task_vals = defaultdict(dict)\n",
    "    \n",
    "    for task in dataset.lens.keys():\n",
    "        \n",
    "        task_loss, task_acc, task_f1 = [], [], []\n",
    "        for i in range(config['n_eval_per_task']):\n",
    "            \n",
    "            sample_loss, sample_acc, sample_f1 = [], [], []\n",
    "\n",
    "            support_loader, query_loader = dataset.get_dataloader(task, k=k, tokenizer=tokenizer, shuffle=True)\n",
    "\n",
    "            # Inner loop\n",
    "            # Support set\n",
    "            batch = next(support_loader)\n",
    "            labels, text, attn_mask = batch\n",
    "\n",
    "            #model.train()\n",
    "            model.adapt(labels, text, attn_mask, task_name=task)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for ii in range(config['n_eval_per_support']):\n",
    "                    query_batch = next(query_loader)\n",
    "                    q_labels, q_text, q_attn_mask = query_batch\n",
    "\n",
    "                    logits = model(q_text, q_attn_mask)\n",
    "                    loss = model.lossfn(logits, q_labels)\n",
    "\n",
    "                    mets = logging_metrics(logits.detach().cpu(), q_labels.detach().cpu())\n",
    "\n",
    "                    sample_loss.append(loss.item())\n",
    "                    sample_acc.append(mets['acc'] * 100)\n",
    "                    sample_f1.append(mets['f1'] * 100)\n",
    "\n",
    "            task_loss.append(np.mean(sample_loss))\n",
    "            task_acc.append(np.mean(sample_acc))\n",
    "            task_f1.append(np.mean(sample_f1))\n",
    "            #print('Task {:}: {:}/{:} | Loss {:.4E}, Acc {:5.2f}, F1 {:5.2f}'.format(task, i+1, config['n_eval_per_task'], \\\n",
    "            #    task_loss[-1], task_acc[-1], task_f1[-1]))\n",
    "\n",
    "        print(u\"Eval | Task {:} | Loss {:.2E} \\u00B1 {:.2E}, Acc {:5.2f} \\u00B1 {:4.2f}, F1 {:5.2f} \\u00B1 {:4.2f}\".format(task, \\\n",
    "            np.mean(task_loss), np.std(task_loss), np.mean(task_acc), np.std(task_acc), np.mean(task_f1), np.std(task_f1)))\n",
    "        \n",
    "        task_vals['loss'][task] = np.mean(task_loss)\n",
    "        task_vals['acc'][task] = np.mean(task_acc)\n",
    "        task_vals['f1'][task] = np.mean(task_f1)\n",
    "\n",
    "    return task_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "### HANDLE WITH ARGPARSER #####################\n",
    "###############################################\n",
    "\n",
    "# Emulate config file\n",
    "config = {'encoder_name': 'bert-base-uncased', \n",
    "'nu': 5,\n",
    "'hidden_dims': [256, 128],\n",
    "'act_fn': 'Tanh',\n",
    "'n_inner': 7,\n",
    "'n_outer': 1,\n",
    "'max_episodes': 2500,\n",
    "'min_episodes': 250,\n",
    "'patience': 2,\n",
    "'inner_lr': 1e-3,\n",
    "'output_lr': 1e-3,\n",
    "'meta_lr': 1e-3,\n",
    "'warm_up_steps': 250,\n",
    "'n_eval_per_task': 10,\n",
    "'n_eval_per_support': 1,\n",
    "'checkpoint_path': './checkpoints/ProtoMAML',\n",
    "'version': 'grounded_emotions_test',\n",
    "'include': ['grounded_emotions'],\n",
    "'k': 16,\n",
    "'eval_every_n': 50\n",
    "}\n",
    "\n",
    "config['lossfn'] = nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving models and logs to ./checkpoints/ProtoMAML\\grounded_emotions_test\n"
     ]
    }
   ],
   "source": [
    "# Make sure the right directory structure exists\n",
    "log_dir = os.path.join(config['checkpoint_path'], config['version'])\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(log_dir, 'tensorboard'), exist_ok=True)\n",
    "os.makedirs(os.path.join(log_dir, 'checkpoint'), exist_ok=True)\n",
    "print(f\"Saving models and logs to {log_dir}\")\n",
    "\n",
    "# Build the tensorboard writer\n",
    "writer = SummaryWriter(os.path.join(log_dir, 'tensorboard'))\n",
    "\n",
    "# Load in the data\n",
    "dataset = unified_emotion(\"./data/datasets/unified-dataset.jsonl\", include=config['include'])\n",
    "dataset.prep(text_tokenizer=manual_tokenizer)\n",
    "\n",
    "# Initialization of model\n",
    "model = ProtoMAMLSeqTransformer(config)\n",
    "\n",
    "#checkpoint_name = \"ProtoMAML_episode-{:}_macrof1-{:5.2f}\".format(9, 33.50)\n",
    "#torch.save(model.state_dict(), './checkpoints/ProtoMAML/unified_test/checkpoint/' + checkpoint_name )\n",
    "#model.load_state_dict(torch.load('./checkpoints/ProtoMAML/unified_test/checkpoint/' + checkpoint_name))\n",
    "\n",
    "# Huggingface tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['encoder_name'])\n",
    "\n",
    "# Meta optimizers\n",
    "shared_optimizer = optim.SGD(model.model_shared.parameters(), lr=config['meta_lr'])\n",
    "shared_lr_schedule = get_constant_schedule_with_warmup(shared_optimizer, config['warm_up_steps'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6.67\n",
      "Train | Episode 13 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9448E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 14 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8656E-01, Acc 53.12, F1 43.86\n",
      "Train | Episode 15 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0271E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 16 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0381E-01, Acc 50.00, F1 38.16\n",
      "Train | Episode 17 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9342E-01, Acc 50.00, F1 38.16\n",
      "Train | Episode 18 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9851E-01, Acc 50.00, F1 38.16\n",
      "Train | Episode 19 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0027E-01, Acc 46.88, F1 36.37\n",
      "Train | Episode 20 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9176E-01, Acc 53.12, F1 51.95\n",
      "Train | Episode 21 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9138E-01, Acc 59.38, F1 51.35\n",
      "Train | Episode 22 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8932E-01, Acc 53.12, F1 49.10\n",
      "Train | Episode 23 | Task 1/1: grounded_emotions   , N=2 | Loss 7.3607E-01, Acc 46.88, F1 44.21\n",
      "Train | Episode 24 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0348E-01, Acc 40.62, F1 32.67\n",
      "Train | Episode 25 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9406E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 26 | Task 1/1: grounded_emotions   , N=2 | Loss 6.7310E-01, Acc 62.50, F1 60.00\n",
      "Train | Episode 27 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9980E-01, Acc 53.12, F1 39.92\n",
      "Train | Episode 28 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8286E-01, Acc 68.75, F1 66.67\n",
      "Train | Episode 29 | Task 1/1: grounded_emotions   , N=2 | Loss 7.5086E-01, Acc 37.50, F1 30.74\n",
      "Train | Episode 30 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9340E-01, Acc 53.12, F1 51.95\n",
      "Train | Episode 31 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0244E-01, Acc 46.88, F1 46.82\n",
      "Train | Episode 32 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9003E-01, Acc 50.00, F1 38.16\n",
      "Train | Episode 33 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8147E-01, Acc 53.12, F1 49.10\n",
      "Train | Episode 34 | Task 1/1: grounded_emotions   , N=2 | Loss 7.7629E-01, Acc 43.75, F1 43.75\n",
      "Train | Episode 35 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8453E-01, Acc 68.75, F1 68.75\n",
      "Train | Episode 36 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9624E-01, Acc 50.00, F1 38.16\n",
      "Train | Episode 37 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8812E-01, Acc 46.88, F1 36.37\n",
      "Train | Episode 38 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8908E-01, Acc 59.38, F1 59.01\n",
      "Train | Episode 39 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9229E-01, Acc 62.50, F1 61.13\n",
      "Train | Episode 40 | Task 1/1: grounded_emotions   , N=2 | Loss 7.1470E-01, Acc 46.88, F1 39.76\n",
      "Train | Episode 41 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9311E-01, Acc 50.00, F1 49.21\n",
      "Train | Episode 42 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9405E-01, Acc 43.75, F1 40.00\n",
      "Train | Episode 43 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8304E-01, Acc 53.12, F1 46.84\n",
      "Train | Episode 44 | Task 1/1: grounded_emotions   , N=2 | Loss 7.4094E-01, Acc 37.50, F1 35.22\n",
      "Train | Episode 45 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9368E-01, Acc 43.75, F1 41.70\n",
      "Train | Episode 46 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9260E-01, Acc 56.25, F1 45.89\n",
      "Train | Episode 47 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0102E-01, Acc 46.88, F1 44.21\n",
      "Train | Episode 48 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9122E-01, Acc 59.38, F1 59.34\n",
      "Train | Episode 49 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9491E-01, Acc 50.00, F1 48.18\n",
      "Train | Episode 50 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0403E-01, Acc 46.88, F1 39.76\n",
      "Eval | Task grounded_emotions | Loss 6.98E-01  0.00E+00, Acc 49.38  0.00, F1 35.87  0.00\n",
      "\n",
      "Model did not improve with macrof1=35.87388873100281\n",
      "Train | Episode 51 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0606E-01, Acc 50.00, F1 46.67\n",
      "Train | Episode 52 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8544E-01, Acc 46.88, F1 44.21\n",
      "Train | Episode 53 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0462E-01, Acc 46.88, F1 31.91\n",
      "Train | Episode 54 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9348E-01, Acc 53.12, F1 52.71\n",
      "Train | Episode 55 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9439E-01, Acc 46.88, F1 45.55\n",
      "Train | Episode 56 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9049E-01, Acc 56.25, F1 56.08\n",
      "Train | Episode 57 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9010E-01, Acc 50.00, F1 41.82\n",
      "Train | Episode 58 | Task 1/1: grounded_emotions   , N=2 | Loss 6.6628E-01, Acc 56.25, F1 55.56\n",
      "Train | Episode 59 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9127E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 60 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8504E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 61 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9868E-01, Acc 50.00, F1 49.21\n",
      "Train | Episode 62 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8452E-01, Acc 56.25, F1 56.08\n",
      "Train | Episode 63 | Task 1/1: grounded_emotions   , N=2 | Loss 7.1033E-01, Acc 43.75, F1 37.66\n",
      "Train | Episode 64 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9220E-01, Acc 56.25, F1 56.25\n",
      "Train | Episode 65 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9704E-01, Acc 59.38, F1 51.35\n",
      "Train | Episode 66 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9606E-01, Acc 46.88, F1 36.37\n",
      "Train | Episode 67 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8799E-01, Acc 56.25, F1 49.09\n",
      "Train | Episode 68 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9224E-01, Acc 40.62, F1 40.57\n",
      "Train | Episode 69 | Task 1/1: grounded_emotions   , N=2 | Loss 7.2434E-01, Acc 56.25, F1 56.08\n",
      "Train | Episode 70 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9648E-01, Acc 53.12, F1 52.71\n",
      "Train | Episode 71 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9747E-01, Acc 50.00, F1 48.18\n",
      "Train | Episode 72 | Task 1/1: grounded_emotions   , N=2 | Loss 7.1331E-01, Acc 50.00, F1 49.21\n",
      "Train | Episode 73 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9622E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 74 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0311E-01, Acc 53.12, F1 52.71\n",
      "Train | Episode 75 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0971E-01, Acc 46.88, F1 46.40\n",
      "Train | Episode 76 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8117E-01, Acc 62.50, F1 61.13\n",
      "Train | Episode 77 | Task 1/1: grounded_emotions   , N=2 | Loss 7.1205E-01, Acc 46.88, F1 31.91\n",
      "Train | Episode 78 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9065E-01, Acc 50.00, F1 49.80\n",
      "Train | Episode 79 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8847E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 80 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9439E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 81 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9555E-01, Acc 50.00, F1 38.16\n",
      "Train | Episode 82 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9031E-01, Acc 56.25, F1 55.56\n",
      "Train | Episode 83 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8866E-01, Acc 50.00, F1 38.16\n",
      "Train | Episode 84 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9238E-01, Acc 50.00, F1 48.18\n",
      "Train | Episode 85 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9687E-01, Acc 50.00, F1 38.16\n",
      "Train | Episode 86 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0304E-01, Acc 50.00, F1 50.00\n",
      "Train | Episode 87 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9794E-01, Acc 40.62, F1 35.52\n",
      "Train | Episode 88 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9993E-01, Acc 53.12, F1 39.92\n",
      "Train | Episode 89 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0914E-01, Acc 43.75, F1 40.00\n",
      "Train | Episode 90 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9852E-01, Acc 46.88, F1 39.76\n",
      "Train | Episode 91 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9642E-01, Acc 43.75, F1 37.66\n",
      "Train | Episode 92 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9291E-01, Acc 50.00, F1 48.18\n",
      "Train | Episode 93 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9612E-01, Acc 50.00, F1 41.82\n",
      "Train | Episode 94 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0127E-01, Acc 53.12, F1 52.71\n",
      "Train | Episode 95 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9826E-01, Acc 50.00, F1 41.82\n",
      "Train | Episode 96 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9303E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 97 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0474E-01, Acc 56.25, F1 54.66\n",
      "Train | Episode 98 | Task 1/1: grounded_emotions   , N=2 | Loss 7.1080E-01, Acc 46.88, F1 39.76\n",
      "Train | Episode 99 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9348E-01, Acc 56.25, F1 45.89\n",
      "Train | Episode 100 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9211E-01, Acc 59.38, F1 57.33\n",
      "Eval | Task grounded_emotions | Loss 7.11E-01  0.00E+00, Acc 46.25  0.00, F1 44.13  0.00\n",
      "\n",
      "Model did not improve with macrof1=44.12963092327118\n",
      "Train | Episode 101 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8854E-01, Acc 46.88, F1 42.31\n",
      "Train | Episode 102 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9651E-01, Acc 53.12, F1 52.71\n",
      "Train | Episode 103 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9184E-01, Acc 50.00, F1 38.16\n",
      "Train | Episode 104 | Task 1/1: grounded_emotions   , N=2 | Loss 7.1927E-01, Acc 43.75, F1 30.43\n",
      "Train | Episode 105 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9846E-01, Acc 46.88, F1 31.91\n",
      "Train | Episode 106 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8968E-01, Acc 53.12, F1 50.77\n",
      "Train | Episode 107 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9408E-01, Acc 50.00, F1 38.16\n",
      "Train | Episode 108 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9379E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 109 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0441E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 110 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0080E-01, Acc 53.12, F1 52.71\n",
      "Train | Episode 111 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9885E-01, Acc 34.38, F1 31.08\n",
      "Train | Episode 112 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9547E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 113 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9539E-01, Acc 50.00, F1 48.18\n",
      "Train | Episode 114 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0072E-01, Acc 46.88, F1 36.37\n",
      "Train | Episode 115 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9038E-01, Acc 50.00, F1 46.67\n",
      "Train | Episode 116 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8151E-01, Acc 53.12, F1 39.92\n",
      "Train | Episode 117 | Task 1/1: grounded_emotions   , N=2 | Loss 7.2510E-01, Acc 40.62, F1 40.10\n",
      "Train | Episode 118 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9146E-01, Acc 56.25, F1 55.56\n",
      "Train | Episode 119 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8628E-01, Acc 59.38, F1 53.93\n",
      "Train | Episode 120 | Task 1/1: grounded_emotions   , N=2 | Loss 6.7910E-01, Acc 56.25, F1 51.52\n",
      "Train | Episode 121 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0210E-01, Acc 46.88, F1 36.37\n",
      "Train | Episode 122 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0031E-01, Acc 56.25, F1 49.09\n",
      "Train | Episode 123 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8987E-01, Acc 50.00, F1 41.82\n",
      "Train | Episode 124 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9346E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 125 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8468E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 126 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0441E-01, Acc 46.88, F1 31.91\n",
      "Train | Episode 127 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9721E-01, Acc 46.88, F1 31.91\n",
      "Train | Episode 128 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0116E-01, Acc 46.88, F1 31.91\n",
      "Train | Episode 129 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9741E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 130 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9387E-01, Acc 50.00, F1 41.82\n",
      "Train | Episode 131 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9098E-01, Acc 43.75, F1 34.55\n",
      "Train | Episode 132 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8591E-01, Acc 59.38, F1 58.36\n",
      "Train | Episode 133 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9789E-01, Acc 46.88, F1 44.21\n",
      "Train | Episode 134 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9398E-01, Acc 50.00, F1 38.16\n",
      "Train | Episode 135 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8584E-01, Acc 53.12, F1 39.92\n",
      "Train | Episode 136 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8575E-01, Acc 68.75, F1 67.61\n",
      "Train | Episode 137 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9823E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 138 | Task 1/1: grounded_emotions   , N=2 | Loss 7.3565E-01, Acc 43.75, F1 41.70\n",
      "Train | Episode 139 | Task 1/1: grounded_emotions   , N=2 | Loss 7.1584E-01, Acc 43.75, F1 37.66\n",
      "Train | Episode 140 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0045E-01, Acc 40.62, F1 32.67\n",
      "Train | Episode 141 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9450E-01, Acc 43.75, F1 41.70\n",
      "Train | Episode 142 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9898E-01, Acc 46.88, F1 42.31\n",
      "Train | Episode 143 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9176E-01, Acc 50.00, F1 48.18\n",
      "Train | Episode 144 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8656E-01, Acc 56.25, F1 53.33\n",
      "Train | Episode 145 | Task 1/1: grounded_emotions   , N=2 | Loss 6.7600E-01, Acc 59.38, F1 59.34\n",
      "Train | Episode 146 | Task 1/1: grounded_emotions   , N=2 | Loss 7.1213E-01, Acc 53.12, F1 50.77\n",
      "Train | Episode 147 | Task 1/1: grounded_emotions   , N=2 | Loss 7.1962E-01, Acc 43.75, F1 41.70\n",
      "Train | Episode 148 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9578E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 149 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9755E-01, Acc 46.88, F1 39.76\n",
      "Train | Episode 150 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0011E-01, Acc 50.00, F1 38.16\n",
      "Eval | Task grounded_emotions | Loss 6.90E-01  0.00E+00, Acc 50.62  0.00, F1 41.25  0.00\n",
      "\n",
      "Model did not improve with macrof1=41.246792674064636\n",
      "Train | Episode 151 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9791E-01, Acc 46.88, F1 42.31\n",
      "Train | Episode 152 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9793E-01, Acc 50.00, F1 38.16\n",
      "Train | Episode 153 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0224E-01, Acc 37.50, F1 37.25\n",
      "Train | Episode 154 | Task 1/1: grounded_emotions   , N=2 | Loss 7.1060E-01, Acc 46.88, F1 31.91\n",
      "Train | Episode 155 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9101E-01, Acc 56.25, F1 51.52\n",
      "Train | Episode 156 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9689E-01, Acc 53.12, F1 39.92\n",
      "Train | Episode 157 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9657E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 158 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9202E-01, Acc 59.38, F1 58.36\n",
      "Train | Episode 159 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9431E-01, Acc 43.75, F1 42.86\n",
      "Train | Episode 160 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9594E-01, Acc 40.62, F1 37.64\n",
      "Train | Episode 161 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0932E-01, Acc 43.75, F1 43.75\n",
      "Train | Episode 162 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9530E-01, Acc 40.62, F1 37.64\n",
      "Train | Episode 163 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8923E-01, Acc 50.00, F1 48.18\n",
      "Train | Episode 164 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9735E-01, Acc 50.00, F1 41.82\n",
      "Train | Episode 165 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9154E-01, Acc 56.25, F1 45.89\n",
      "Train | Episode 166 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0081E-01, Acc 46.88, F1 39.76\n",
      "Train | Episode 167 | Task 1/1: grounded_emotions   , N=2 | Loss 7.1017E-01, Acc 43.75, F1 34.55\n",
      "Train | Episode 168 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0348E-01, Acc 50.00, F1 38.16\n",
      "Train | Episode 169 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9277E-01, Acc 53.12, F1 51.95\n",
      "Train | Episode 170 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0482E-01, Acc 50.00, F1 44.59\n",
      "Train | Episode 171 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9549E-01, Acc 56.25, F1 56.08\n",
      "Train | Episode 172 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9996E-01, Acc 50.00, F1 44.59\n",
      "Train | Episode 173 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9657E-01, Acc 53.12, F1 39.92\n",
      "Train | Episode 174 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0084E-01, Acc 40.62, F1 40.10\n",
      "Train | Episode 175 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9051E-01, Acc 56.25, F1 45.89\n",
      "Train | Episode 176 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8525E-01, Acc 53.12, F1 46.84\n",
      "Train | Episode 177 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9056E-01, Acc 56.25, F1 53.33\n",
      "Train | Episode 178 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0335E-01, Acc 43.75, F1 40.00\n",
      "Train | Episode 179 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8693E-01, Acc 56.25, F1 54.66\n",
      "Train | Episode 180 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9213E-01, Acc 46.88, F1 31.91\n",
      "Train | Episode 181 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9718E-01, Acc 53.12, F1 46.84\n",
      "Train | Episode 182 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9670E-01, Acc 53.12, F1 49.10\n",
      "Train | Episode 183 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9446E-01, Acc 53.12, F1 39.92\n",
      "Train | Episode 184 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9437E-01, Acc 50.00, F1 50.00\n",
      "Train | Episode 185 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9206E-01, Acc 56.25, F1 45.89\n",
      "Train | Episode 186 | Task 1/1: grounded_emotions   , N=2 | Loss 7.5590E-01, Acc 40.62, F1 40.57\n",
      "Train | Episode 187 | Task 1/1: grounded_emotions   , N=2 | Loss 6.6271E-01, Acc 75.00, F1 74.60\n",
      "Train | Episode 188 | Task 1/1: grounded_emotions   , N=2 | Loss 7.1022E-01, Acc 43.75, F1 34.55\n",
      "Train | Episode 189 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9446E-01, Acc 50.00, F1 44.59\n",
      "Train | Episode 190 | Task 1/1: grounded_emotions   , N=2 | Loss 7.1854E-01, Acc 40.62, F1 35.52\n",
      "Train | Episode 191 | Task 1/1: grounded_emotions   , N=2 | Loss 6.7518E-01, Acc 59.38, F1 58.36\n",
      "Train | Episode 192 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9540E-01, Acc 46.88, F1 45.55\n",
      "Train | Episode 193 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9661E-01, Acc 50.00, F1 38.16\n",
      "Train | Episode 194 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8999E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 195 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9535E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 196 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9113E-01, Acc 56.25, F1 53.33\n",
      "Train | Episode 197 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9154E-01, Acc 59.38, F1 58.36\n",
      "Train | Episode 198 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8632E-01, Acc 59.38, F1 58.36\n",
      "Train | Episode 199 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0215E-01, Acc 46.88, F1 39.76\n",
      "Train | Episode 200 | Task 1/1: grounded_emotions   , N=2 | Loss 7.0046E-01, Acc 40.62, F1 35.52\n",
      "Eval | Task grounded_emotions | Loss 6.95E-01  0.00E+00, Acc 46.88  0.00, F1 37.57  0.00\n",
      "\n",
      "Model did not improve with macrof1=37.57308900356293\n",
      "Train | Episode 201 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9806E-01, Acc 40.62, F1 39.14\n",
      "Train | Episode 202 | Task 1/1: grounded_emotions   , N=2 | Loss 7.1729E-01, Acc 34.38, F1 32.73\n",
      "Train | Episode 203 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9994E-01, Acc 53.12, F1 49.10\n",
      "Train | Episode 204 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9897E-01, Acc 40.62, F1 28.89\n",
      "Train | Episode 205 | Task 1/1: grounded_emotions   , N=2 | Loss 6.8351E-01, Acc 56.25, F1 56.08\n",
      "Train | Episode 206 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9942E-01, Acc 53.12, F1 51.95\n",
      "Train | Episode 207 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9944E-01, Acc 50.00, F1 33.33\n",
      "Train | Episode 208 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9043E-01, Acc 53.12, F1 46.84\n",
      "Train | Episode 209 | Task 1/1: grounded_emotions   , N=2 | Loss 6.7863E-01, Acc 62.50, F1 62.35\n",
      "Train | Episode 210 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9507E-01, Acc 46.88, F1 44.21\n",
      "Train | Episode 211 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9106E-01, Acc 53.12, F1 43.86\n",
      "Train | Episode 212 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9264E-01, Acc 53.12, F1 39.92\n",
      "Train | Episode 213 | Task 1/1: grounded_emotions   , N=2 | Loss 6.9926E-01, Acc 46.88, F1 31.91\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-fe8f8e57461e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m#model.train()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msource_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# Outer loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ivoon\\Documents\\GitHub\\meta-learning-emotion-detection\\models\\protomaml_seqtransformer.py\u001b[0m in \u001b[0;36madapt\u001b[1;34m(self, labels, text, attn_mask, task_name, verbose)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;31m# Embed, encode, classify and compute loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlossfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ivoon\\Documents\\GitHub\\meta-learning-emotion-detection\\models\\protomaml_seqtransformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, text, attn_mask)\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No task-specific model specified yet.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_task\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_task\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_task\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ivoon\\Documents\\GitHub\\meta-learning-emotion-detection\\models\\seqtransformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, text, attn_mask)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ivoon\\Documents\\GitHub\\meta-learning-emotion-detection\\modules\\encoders.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, text, attn_mask)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pooler_output'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m         )\n\u001b[1;32m--> 971\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m    972\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    566\u001b[0m                 )\n\u001b[0;32m    567\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    569\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    454\u001b[0m         \u001b[1;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[0;32m    457\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         )\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# add attentions if we output them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\dropout.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[1;34m\"but got {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1076\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Meta-evaluate prior to training for decent baseline\n",
    "meta_eval = meta_evaluate(model, dataset, tokenizer, config, k=config['k'])\n",
    "\n",
    "macro_f1 = np.mean(list(meta_eval['f1'].values()))\n",
    "\n",
    "writer.add_scalars('Loss/MetaEval', meta_eval['loss'], 0)\n",
    "writer.add_scalars('Accuracy/MetaEval', meta_eval['acc'], 0)\n",
    "writer.add_scalars('F1/MetaEval', meta_eval['f1'], 0)\n",
    "writer.add_scalar('MacroF1/MetaEval', 0)\n",
    "\n",
    "best_macro_f1 = macro_f1\n",
    "\n",
    "curr_patience = config['patience']\n",
    "\n",
    "for episode in range(1, config['max_episodes']+1):\n",
    "    ############\n",
    "    # Training #\n",
    "    ############\n",
    "    for ii in range(config['n_outer']):\n",
    "\n",
    "        source_name = dataset_sampler(dataset, sampling_method='sqrt')\n",
    "        support_loader, query_loader = dataset.get_dataloader(source_name, k=config['k'], tokenizer=tokenizer, shuffle=True)\n",
    "\n",
    "        # Inner loop\n",
    "        # Support set\n",
    "        batch = next(query_loader)\n",
    "        labels, text, attn_mask = batch\n",
    "\n",
    "        model.train()\n",
    "        model.adapt(labels, text, attn_mask, task_name=source_name)\n",
    "\n",
    "        # Outer loop\n",
    "        # Query set\n",
    "        query_batch = next(query_loader)\n",
    "        q_labels, q_text, q_attn_mask = query_batch\n",
    "\n",
    "        model.eval()\n",
    "        logits = model(q_text, q_attn_mask)\n",
    "        loss = model.lossfn(logits, q_labels)\n",
    "\n",
    "        model.backward(loss)\n",
    "\n",
    "        # Logging\n",
    "        n_classes = len(dataset.label_map[source_name].keys())\n",
    "        with torch.no_grad():\n",
    "            mets = logging_metrics(logits.detach().cpu(), q_labels.detach().cpu())\n",
    "        print(\"Train | Episode {} | Task {}/{}: {:<20s}, N={} | Loss {:.4E}, Acc {:5.2f}, F1 {:5.2f}\".format(episode, ii+1, \\\n",
    "            config['n_outer'], source_name, n_classes, loss.detach().item(), mets['acc']*100, mets['f1']*100))\n",
    "\n",
    "        writer.add_scalars('Loss/Train', {source_name: loss.detach().item()}, episode)\n",
    "        writer.add_scalars('Accuracy/Train', {source_name: mets['acc']*100}, episode)\n",
    "        writer.add_scalars('F1/Train', {source_name: mets['f1']*100}, episode)\n",
    "\n",
    "    shared_optimizer.step()\n",
    "    shared_lr_schedule.step()\n",
    "    shared_optimizer.zero_grad()\n",
    "    \n",
    "    ##############\n",
    "    # Evaluation #\n",
    "    ##############\n",
    "    if (episode % config['eval_every_n'])== 0:\n",
    "\n",
    "        meta_eval = meta_evaluate(model, dataset, tokenizer, config, k=config['k'])\n",
    "\n",
    "        macro_f1 = np.mean(list(meta_eval['f1'].values()))\n",
    "\n",
    "        writer.add_scalars('Loss/MetaEval', meta_eval['loss'], episode)\n",
    "        writer.add_scalars('Accuracy/MetaEval', meta_eval['acc'], episode)\n",
    "        writer.add_scalars('F1/MetaEval', meta_eval['f1'], episode)\n",
    "        writer.add_scalar('MacroF1/MetaEval', episode+1)\n",
    "\n",
    "        if macro_f1 > best_macro_f1:\n",
    "            save_name = f\"episode-{episode+1}_macrof1-{macro_f1}\"\n",
    "            torch.save(model.state_dict(), os.path.join(log_dir, 'checkpoint', save_name))\n",
    "            \n",
    "            print(f\"Saving model as {save_name}\\nNew best macrof1={best_macro_f1}\")\n",
    "            best_macro_f1 = macro_f1\n",
    "            curr_patience = config['patience']\n",
    "        \n",
    "        else:\n",
    "            print(f\"Model did not improve with macrof1={macro_f1}\")\n",
    "            if episode > config['min_episodes']:\n",
    "                curr_patience -= 1\n",
    "\n",
    "        print('')\n",
    "\n",
    "        if curr_patience < 0:\n",
    "            print(\"Stopping early.\")\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_name = dataset_sampler(dataset, sampling_method='sqrt')\n",
    "_, query_loader = dataset.get_dataloader(source_name, k=k, tokenizer=tokenizer, shuffle=True)\n",
    "query_batch = next(query_loader)\n",
    "q_labels, q_text, q_attn_mask = query_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\tInner 0 | Loss 6.1790E-01\n",
      "\tInner 1 | Loss 5.9264E-01\n",
      "\tInner 2 | Loss 5.5335E-01\n",
      "\tInner 3 | Loss 4.8858E-01\n",
      "\tInner 4 | Loss 4.4266E-01\n",
      "\tInner 5 | Loss 4.2068E-01\n",
      "\tInner 6 | Loss 3.9739E-01\n"
     ]
    }
   ],
   "source": [
    "model.adapt(q_labels, q_text, q_attn_mask, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Task grounded_emotions: 0/1 | Loss 9.1800E-01, Acc 50.00, F1 33.33\nTask grounded_emotions | Loss 9.18E-01  0.00E+00, Acc 50.00  0.00, F1 33.33  0.00\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'loss': {'grounded_emotions': 0.9180004954338074},\n",
       "             'acc': {'grounded_emotions': 50.0},\n",
       "             'f1': {'grounded_emotions': 33.33333432674408}})"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ss 1.6555E-01\n",
      "\tInner 6 | Loss 1.1413E-01\n",
      "Episode 178 | Task 1/1: grounded_emotions   , N=2 | Loss 1.4232E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.1620E+00\n",
      "\tInner 1 | Loss 9.6685E-01\n",
      "\tInner 2 | Loss 9.2296E-01\n",
      "\tInner 3 | Loss 5.0415E-01\n",
      "\tInner 4 | Loss 4.3550E-01\n",
      "\tInner 5 | Loss 3.9371E-01\n",
      "\tInner 6 | Loss 3.5230E-01\n",
      "Episode 179 | Task 1/1: grounded_emotions   , N=2 | Loss 3.3417E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.9479E+00\n",
      "\tInner 1 | Loss 1.9334E+00\n",
      "\tInner 2 | Loss 6.9830E+00\n",
      "\tInner 3 | Loss 5.2546E+00\n",
      "\tInner 4 | Loss 3.2245E+00\n",
      "\tInner 5 | Loss 6.7004E-01\n",
      "\tInner 6 | Loss 4.0514E-01\n",
      "Episode 180 | Task 1/1: grounded_emotions   , N=2 | Loss 6.4351E-02, Acc 96.88, F1 96.87\n",
      "\tInner 0 | Loss 1.9669E+00\n",
      "\tInner 1 | Loss 3.3779E+00\n",
      "\tInner 2 | Loss 2.3926E+00\n",
      "\tInner 3 | Loss 8.3337E-01\n",
      "\tInner 4 | Loss 6.4106E-01\n",
      "\tInner 5 | Loss 5.0155E-01\n",
      "\tInner 6 | Loss 4.2214E-01\n",
      "Episode 181 | Task 1/1: grounded_emotions   , N=2 | Loss 1.4522E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.3844E+00\n",
      "\tInner 1 | Loss 7.5845E-01\n",
      "\tInner 2 | Loss 5.3623E-01\n",
      "\tInner 3 | Loss 5.2989E-01\n",
      "\tInner 4 | Loss 1.0131E+00\n",
      "\tInner 5 | Loss 4.5554E-01\n",
      "\tInner 6 | Loss 5.6427E-01\n",
      "Episode 182 | Task 1/1: grounded_emotions   , N=2 | Loss 3.0471E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.6425E+00\n",
      "\tInner 1 | Loss 1.7217E+00\n",
      "\tInner 2 | Loss 2.9014E+00\n",
      "\tInner 3 | Loss 9.8036E-01\n",
      "\tInner 4 | Loss 4.3843E-01\n",
      "\tInner 5 | Loss 3.8663E-01\n",
      "\tInner 6 | Loss 3.4047E-01\n",
      "Episode 183 | Task 1/1: grounded_emotions   , N=2 | Loss 1.5986E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.2730E+00\n",
      "\tInner 1 | Loss 1.2781E+00\n",
      "\tInner 2 | Loss 8.9832E-01\n",
      "\tInner 3 | Loss 8.5266E-01\n",
      "\tInner 4 | Loss 6.2279E-01\n",
      "\tInner 5 | Loss 5.4505E-01\n",
      "\tInner 6 | Loss 2.2859E-01\n",
      "Episode 184 | Task 1/1: grounded_emotions   , N=2 | Loss 4.5395E-02, Acc 96.88, F1 96.87\n",
      "\tInner 0 | Loss 1.8735E+00\n",
      "\tInner 1 | Loss 4.2034E+00\n",
      "\tInner 2 | Loss 2.0377E+00\n",
      "\tInner 3 | Loss 5.9608E-01\n",
      "\tInner 4 | Loss 4.4923E-01\n",
      "\tInner 5 | Loss 4.3781E-01\n",
      "\tInner 6 | Loss 3.9987E-01\n",
      "Episode 185 | Task 1/1: grounded_emotions   , N=2 | Loss 1.6987E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.8173E+00\n",
      "\tInner 1 | Loss 1.7565E+00\n",
      "\tInner 2 | Loss 1.9814E+00\n",
      "\tInner 3 | Loss 5.8855E-01\n",
      "\tInner 4 | Loss 5.3594E-01\n",
      "\tInner 5 | Loss 6.4096E-01\n",
      "\tInner 6 | Loss 3.9829E-01\n",
      "Episode 186 | Task 1/1: grounded_emotions   , N=2 | Loss 1.0567E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 6.9066E-01\n",
      "\tInner 1 | Loss 6.8806E-01\n",
      "\tInner 2 | Loss 6.8530E-01\n",
      "\tInner 3 | Loss 6.8244E-01\n",
      "\tInner 4 | Loss 6.8011E-01\n",
      "\tInner 5 | Loss 6.7814E-01\n",
      "\tInner 6 | Loss 6.7624E-01\n",
      "Episode 187 | Task 1/1: grounded_emotions   , N=2 | Loss 5.0380E-01, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.1395E+00\n",
      "\tInner 1 | Loss 2.4600E+00\n",
      "\tInner 2 | Loss 2.9996E+00\n",
      "\tInner 3 | Loss 7.5819E-01\n",
      "\tInner 4 | Loss 4.7550E-01\n",
      "\tInner 5 | Loss 3.4629E-01\n",
      "\tInner 6 | Loss 2.4853E-01\n",
      "Episode 188 | Task 1/1: grounded_emotions   , N=2 | Loss 1.4301E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.9129E+00\n",
      "\tInner 1 | Loss 2.7697E+00\n",
      "\tInner 2 | Loss 3.0260E+00\n",
      "\tInner 3 | Loss 1.3821E+00\n",
      "\tInner 4 | Loss 5.2627E-01\n",
      "\tInner 5 | Loss 4.2462E-01\n",
      "\tInner 6 | Loss 3.4952E-01\n",
      "Episode 189 | Task 1/1: grounded_emotions   , N=2 | Loss 1.4914E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.1283E+00\n",
      "\tInner 1 | Loss 1.0869E+00\n",
      "\tInner 2 | Loss 6.1979E-01\n",
      "\tInner 3 | Loss 5.4016E-01\n",
      "\tInner 4 | Loss 9.1828E-01\n",
      "\tInner 5 | Loss 7.9202E-01\n",
      "\tInner 6 | Loss 1.3591E+00\n",
      "Episode 190 | Task 1/1: grounded_emotions   , N=2 | Loss 1.2755E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.9441E+00\n",
      "\tInner 1 | Loss 1.1713E+00\n",
      "\tInner 2 | Loss 1.6110E+00\n",
      "\tInner 3 | Loss 6.5680E-01\n",
      "\tInner 4 | Loss 7.9566E-01\n",
      "\tInner 5 | Loss 4.8604E-01\n",
      "\tInner 6 | Loss 4.2870E-01\n",
      "Episode 191 | Task 1/1: grounded_emotions   , N=2 | Loss 1.5832E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.0640E+00\n",
      "\tInner 1 | Loss 2.7416E+00\n",
      "\tInner 2 | Loss 1.0071E+00\n",
      "\tInner 3 | Loss 1.0625E+00\n",
      "\tInner 4 | Loss 5.0848E-01\n",
      "\tInner 5 | Loss 3.9166E-01\n",
      "\tInner 6 | Loss 3.0140E-01\n",
      "Episode 192 | Task 1/1: grounded_emotions   , N=2 | Loss 4.5390E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.1553E+00\n",
      "\tInner 1 | Loss 1.1578E+00\n",
      "\tInner 2 | Loss 1.6437E+00\n",
      "\tInner 3 | Loss 2.9913E+00\n",
      "\tInner 4 | Loss 8.7223E-01\n",
      "\tInner 5 | Loss 4.0112E-01\n",
      "\tInner 6 | Loss 3.0834E-01\n",
      "Episode 193 | Task 1/1: grounded_emotions   , N=2 | Loss 1.1886E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.8087E+00\n",
      "\tInner 1 | Loss 1.2408E+00\n",
      "\tInner 2 | Loss 1.1030E+00\n",
      "\tInner 3 | Loss 7.3463E-01\n",
      "\tInner 4 | Loss 8.0011E-01\n",
      "\tInner 5 | Loss 6.2317E-01\n",
      "\tInner 6 | Loss 5.5202E-01\n",
      "Episode 194 | Task 1/1: grounded_emotions   , N=2 | Loss 3.5705E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.0550E+00\n",
      "\tInner 1 | Loss 7.2051E-01\n",
      "\tInner 2 | Loss 7.5147E-01\n",
      "\tInner 3 | Loss 8.4901E-01\n",
      "\tInner 4 | Loss 5.3300E-01\n",
      "\tInner 5 | Loss 4.9175E-01\n",
      "\tInner 6 | Loss 4.5371E-01\n",
      "Episode 195 | Task 1/1: grounded_emotions   , N=2 | Loss 6.2412E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.9902E+00\n",
      "\tInner 1 | Loss 4.7570E+00\n",
      "\tInner 2 | Loss 1.3184E+00\n",
      "\tInner 3 | Loss 1.1489E+00\n",
      "\tInner 4 | Loss 9.2688E-01\n",
      "\tInner 5 | Loss 1.3209E+00\n",
      "\tInner 6 | Loss 3.7814E-01\n",
      "Episode 196 | Task 1/1: grounded_emotions   , N=2 | Loss 8.1335E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.0060E+00\n",
      "\tInner 1 | Loss 8.6314E-01\n",
      "\tInner 2 | Loss 7.6147E-01\n",
      "\tInner 3 | Loss 6.9849E-01\n",
      "\tInner 4 | Loss 6.3553E-01\n",
      "\tInner 5 | Loss 5.8921E-01\n",
      "\tInner 6 | Loss 5.4978E-01\n",
      "Episode 197 | Task 1/1: grounded_emotions   , N=2 | Loss 5.7340E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.5021E+00\n",
      "\tInner 1 | Loss 1.4158E+00\n",
      "\tInner 2 | Loss 8.1930E-01\n",
      "\tInner 3 | Loss 4.6790E-01\n",
      "\tInner 4 | Loss 1.2426E+00\n",
      "\tInner 5 | Loss 5.8224E+00\n",
      "\tInner 6 | Loss 1.9516E+00\n",
      "Episode 198 | Task 1/1: grounded_emotions   , N=2 | Loss 7.3622E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.4353E+00\n",
      "\tInner 1 | Loss 1.1906E+00\n",
      "\tInner 2 | Loss 9.9634E-01\n",
      "\tInner 3 | Loss 8.1459E-01\n",
      "\tInner 4 | Loss 6.4631E-01\n",
      "\tInner 5 | Loss 3.8736E-01\n",
      "\tInner 6 | Loss 3.3779E-01\n",
      "Episode 199 | Task 1/1: grounded_emotions   , N=2 | Loss 2.9541E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.0498E+00\n",
      "\tInner 1 | Loss 6.3521E+00\n",
      "\tInner 2 | Loss 4.2636E+00\n",
      "\tInner 3 | Loss 1.4824E+00\n",
      "\tInner 4 | Loss 1.2561E+00\n",
      "\tInner 5 | Loss 7.1783E-01\n",
      "\tInner 6 | Loss 6.2842E-01\n",
      "Episode 200 | Task 1/1: grounded_emotions   , N=2 | Loss 6.6031E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.0356E+00\n",
      "\tInner 1 | Loss 3.8232E+00\n",
      "\tInner 2 | Loss 3.6181E+00\n",
      "\tInner 3 | Loss 5.9330E-01\n",
      "\tInner 4 | Loss 4.6115E-01\n",
      "\tInner 5 | Loss 3.6706E-01\n",
      "\tInner 6 | Loss 1.3500E-01\n",
      "Episode 201 | Task 1/1: grounded_emotions   , N=2 | Loss 1.3205E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.3736E+00\n",
      "\tInner 1 | Loss 9.5014E-01\n",
      "\tInner 2 | Loss 2.9252E-01\n",
      "\tInner 3 | Loss 5.3620E-01\n",
      "\tInner 4 | Loss 3.8665E+00\n",
      "\tInner 5 | Loss 4.0794E+00\n",
      "\tInner 6 | Loss 2.2191E-01\n",
      "Episode 202 | Task 1/1: grounded_emotions   , N=2 | Loss 5.5996E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.4057E+00\n",
      "\tInner 1 | Loss 2.2871E+00\n",
      "\tInner 2 | Loss 3.4458E+00\n",
      "\tInner 3 | Loss 1.1018E+00\n",
      "\tInner 4 | Loss 7.2056E-01\n",
      "\tInner 5 | Loss 5.8543E-01\n",
      "\tInner 6 | Loss 4.8315E-01\n",
      "Episode 203 | Task 1/1: grounded_emotions   , N=2 | Loss 8.1696E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.9767E+00\n",
      "\tInner 1 | Loss 2.7948E+00\n",
      "\tInner 2 | Loss 6.6537E+00\n",
      "\tInner 3 | Loss 3.5573E+00\n",
      "\tInner 4 | Loss 9.2185E-01\n",
      "\tInner 5 | Loss 6.1383E-01\n",
      "\tInner 6 | Loss 3.5924E-01\n",
      "Episode 204 | Task 1/1: grounded_emotions   , N=2 | Loss 1.3830E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 7.1229E-01\n",
      "\tInner 1 | Loss 6.4960E-01\n",
      "\tInner 2 | Loss 6.2604E-01\n",
      "\tInner 3 | Loss 5.9651E-01\n",
      "\tInner 4 | Loss 5.7058E-01\n",
      "\tInner 5 | Loss 5.5069E-01\n",
      "\tInner 6 | Loss 5.3728E-01\n",
      "Episode 205 | Task 1/1: grounded_emotions   , N=2 | Loss 2.8200E-01, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.3465E+00\n",
      "\tInner 1 | Loss 1.0089E+00\n",
      "\tInner 2 | Loss 7.6351E-01\n",
      "\tInner 3 | Loss 5.8140E-01\n",
      "\tInner 4 | Loss 4.8811E-01\n",
      "\tInner 5 | Loss 4.3672E-01\n",
      "\tInner 6 | Loss 4.1204E-01\n",
      "Episode 206 | Task 1/1: grounded_emotions   , N=2 | Loss 1.2120E-01, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 9.7074E-01\n",
      "\tInner 1 | Loss 9.0922E-01\n",
      "\tInner 2 | Loss 8.5150E-01\n",
      "\tInner 3 | Loss 7.9900E-01\n",
      "\tInner 4 | Loss 7.4702E-01\n",
      "\tInner 5 | Loss 7.0166E-01\n",
      "\tInner 6 | Loss 6.6066E-01\n",
      "Episode 207 | Task 1/1: grounded_emotions   , N=2 | Loss 4.5757E-01, Acc 75.00, F1 73.33\n",
      "\tInner 0 | Loss 1.9674E+00\n",
      "\tInner 1 | Loss 8.4593E-01\n",
      "\tInner 2 | Loss 5.3411E-01\n",
      "\tInner 3 | Loss 4.3362E-01\n",
      "\tInner 4 | Loss 3.3210E-01\n",
      "\tInner 5 | Loss 2.7854E-01\n",
      "\tInner 6 | Loss 2.3226E-01\n",
      "Episode 208 | Task 1/1: grounded_emotions   , N=2 | Loss 1.9061E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.1550E+00\n",
      "\tInner 1 | Loss 1.0248E+00\n",
      "\tInner 2 | Loss 8.8392E-01\n",
      "\tInner 3 | Loss 7.6368E-01\n",
      "\tInner 4 | Loss 6.9248E-01\n",
      "\tInner 5 | Loss 6.4520E-01\n",
      "\tInner 6 | Loss 6.1240E-01\n",
      "Episode 209 | Task 1/1: grounded_emotions   , N=2 | Loss 1.5767E-01, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.4665E+00\n",
      "\tInner 1 | Loss 8.8600E-01\n",
      "\tInner 2 | Loss 7.3903E-01\n",
      "\tInner 3 | Loss 6.7226E-01\n",
      "\tInner 4 | Loss 6.1857E-01\n",
      "\tInner 5 | Loss 5.7353E-01\n",
      "\tInner 6 | Loss 5.3526E-01\n",
      "Episode 210 | Task 1/1: grounded_emotions   , N=2 | Loss 5.7600E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.7602E+00\n",
      "\tInner 1 | Loss 1.4019E+00\n",
      "\tInner 2 | Loss 2.2312E+00\n",
      "\tInner 3 | Loss 3.9502E-01\n",
      "\tInner 4 | Loss 2.9925E-01\n",
      "\tInner 5 | Loss 2.0725E-01\n",
      "\tInner 6 | Loss 9.5630E-02\n",
      "Episode 211 | Task 1/1: grounded_emotions   , N=2 | Loss 7.5330E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.8913E+00\n",
      "\tInner 1 | Loss 6.2771E-01\n",
      "\tInner 2 | Loss 5.5330E-01\n",
      "\tInner 3 | Loss 7.0953E-01\n",
      "\tInner 4 | Loss 6.6991E-01\n",
      "\tInner 5 | Loss 1.2830E+00\n",
      "\tInner 6 | Loss 2.9204E-01\n",
      "Episode 212 | Task 1/1: grounded_emotions   , N=2 | Loss 8.2447E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.8529E+00\n",
      "\tInner 1 | Loss 1.0358E+00\n",
      "\tInner 2 | Loss 8.6962E-01\n",
      "\tInner 3 | Loss 7.8440E-01\n",
      "\tInner 4 | Loss 6.1767E-01\n",
      "\tInner 5 | Loss 5.1411E-01\n",
      "\tInner 6 | Loss 4.0405E-01\n",
      "Episode 213 | Task 1/1: grounded_emotions   , N=2 | Loss 2.6518E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.1350E+00\n",
      "\tInner 1 | Loss 8.8917E-01\n",
      "\tInner 2 | Loss 8.0622E-01\n",
      "\tInner 3 | Loss 7.5012E-01\n",
      "\tInner 4 | Loss 7.0351E-01\n",
      "\tInner 5 | Loss 6.6187E-01\n",
      "\tInner 6 | Loss 6.2341E-01\n",
      "Episode 214 | Task 1/1: grounded_emotions   , N=2 | Loss 8.6235E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.7215E+00\n",
      "\tInner 1 | Loss 8.5592E-01\n",
      "\tInner 2 | Loss 7.3037E-01\n",
      "\tInner 3 | Loss 8.0383E-01\n",
      "\tInner 4 | Loss 1.0067E+00\n",
      "\tInner 5 | Loss 4.7373E-01\n",
      "\tInner 6 | Loss 4.3706E-01\n",
      "Episode 215 | Task 1/1: grounded_emotions   , N=2 | Loss 1.8743E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.6404E+00\n",
      "\tInner 1 | Loss 1.0409E+00\n",
      "\tInner 2 | Loss 9.6818E-01\n",
      "\tInner 3 | Loss 6.1174E-01\n",
      "\tInner 4 | Loss 5.1654E-01\n",
      "\tInner 5 | Loss 4.3635E-01\n",
      "\tInner 6 | Loss 3.7076E-01\n",
      "Episode 216 | Task 1/1: grounded_emotions   , N=2 | Loss 1.4780E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.5791E+00\n",
      "\tInner 1 | Loss 4.1431E+00\n",
      "\tInner 2 | Loss 3.6556E+00\n",
      "\tInner 3 | Loss 7.0871E-01\n",
      "\tInner 4 | Loss 5.0563E-01\n",
      "\tInner 5 | Loss 3.2905E-01\n",
      "\tInner 6 | Loss 2.0116E-01\n",
      "Episode 217 | Task 1/1: grounded_emotions   , N=2 | Loss 9.8398E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.1796E+00\n",
      "\tInner 1 | Loss 8.9154E-01\n",
      "\tInner 2 | Loss 7.8817E-01\n",
      "\tInner 3 | Loss 6.2519E-01\n",
      "\tInner 4 | Loss 5.5796E-01\n",
      "\tInner 5 | Loss 4.9325E-01\n",
      "\tInner 6 | Loss 4.1783E-01\n",
      "Episode 218 | Task 1/1: grounded_emotions   , N=2 | Loss 2.8424E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.1863E+00\n",
      "\tInner 1 | Loss 3.6127E+00\n",
      "\tInner 2 | Loss 1.6734E+00\n",
      "\tInner 3 | Loss 1.0384E+00\n",
      "\tInner 4 | Loss 5.8813E-01\n",
      "\tInner 5 | Loss 3.9086E-01\n",
      "\tInner 6 | Loss 3.8281E-01\n",
      "Episode 219 | Task 1/1: grounded_emotions   , N=2 | Loss 9.3132E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.4058E+00\n",
      "\tInner 1 | Loss 2.6415E+00\n",
      "\tInner 2 | Loss 2.1784E+00\n",
      "\tInner 3 | Loss 7.4163E-01\n",
      "\tInner 4 | Loss 4.2796E-01\n",
      "\tInner 5 | Loss 3.3404E-01\n",
      "\tInner 6 | Loss 3.5917E-01\n",
      "Episode 220 | Task 1/1: grounded_emotions   , N=2 | Loss 1.3414E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.1159E+00\n",
      "\tInner 1 | Loss 6.4631E-01\n",
      "\tInner 2 | Loss 5.6598E-01\n",
      "\tInner 3 | Loss 5.2838E-01\n",
      "\tInner 4 | Loss 4.6728E-01\n",
      "\tInner 5 | Loss 4.2534E-01\n",
      "\tInner 6 | Loss 3.9760E-01\n",
      "Episode 221 | Task 1/1: grounded_emotions   , N=2 | Loss 4.4763E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.6215E+00\n",
      "\tInner 1 | Loss 1.0993E+00\n",
      "\tInner 2 | Loss 1.0935E+00\n",
      "\tInner 3 | Loss 1.8651E+00\n",
      "\tInner 4 | Loss 8.1608E-01\n",
      "\tInner 5 | Loss 6.4940E-01\n",
      "\tInner 6 | Loss 5.2793E-01\n",
      "Episode 222 | Task 1/1: grounded_emotions   , N=2 | Loss 4.4421E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.6144E+00\n",
      "\tInner 1 | Loss 1.1263E+00\n",
      "\tInner 2 | Loss 1.4500E+00\n",
      "\tInner 3 | Loss 8.3309E-01\n",
      "\tInner 4 | Loss 1.2880E+00\n",
      "\tInner 5 | Loss 4.7179E-01\n",
      "\tInner 6 | Loss 6.3221E-01\n",
      "Episode 223 | Task 1/1: grounded_emotions   , N=2 | Loss 1.1171E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.6184E+00\n",
      "\tInner 1 | Loss 5.3415E+00\n",
      "\tInner 2 | Loss 7.7938E-01\n",
      "\tInner 3 | Loss 6.9414E-01\n",
      "\tInner 4 | Loss 4.5344E-01\n",
      "\tInner 5 | Loss 3.9103E-01\n",
      "\tInner 6 | Loss 2.8004E-01\n",
      "Episode 224 | Task 1/1: grounded_emotions   , N=2 | Loss 4.7753E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.4464E+00\n",
      "\tInner 1 | Loss 1.0815E+00\n",
      "\tInner 2 | Loss 1.0878E+00\n",
      "\tInner 3 | Loss 5.5830E-01\n",
      "\tInner 4 | Loss 4.6522E-01\n",
      "\tInner 5 | Loss 3.8990E-01\n",
      "\tInner 6 | Loss 3.3257E-01\n",
      "Episode 225 | Task 1/1: grounded_emotions   , N=2 | Loss 1.7965E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.1456E+00\n",
      "\tInner 1 | Loss 4.4033E+00\n",
      "\tInner 2 | Loss 2.5444E+00\n",
      "\tInner 3 | Loss 9.7840E-01\n",
      "\tInner 4 | Loss 1.0810E+00\n",
      "\tInner 5 | Loss 7.1275E-01\n",
      "\tInner 6 | Loss 5.8811E-01\n",
      "Episode 226 | Task 1/1: grounded_emotions   , N=2 | Loss 1.1106E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.6268E+00\n",
      "\tInner 1 | Loss 2.2464E+00\n",
      "\tInner 2 | Loss 2.7661E+00\n",
      "\tInner 3 | Loss 8.0674E-01\n",
      "\tInner 4 | Loss 5.5032E-01\n",
      "\tInner 5 | Loss 3.6271E-01\n",
      "\tInner 6 | Loss 5.0288E-01\n",
      "Episode 227 | Task 1/1: grounded_emotions   , N=2 | Loss 8.9633E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.0930E+00\n",
      "\tInner 1 | Loss 1.4529E+00\n",
      "\tInner 2 | Loss 1.1358E+00\n",
      "\tInner 3 | Loss 8.1068E-01\n",
      "\tInner 4 | Loss 1.0323E+00\n",
      "\tInner 5 | Loss 4.8722E-01\n",
      "\tInner 6 | Loss 3.3957E-01\n",
      "Episode 228 | Task 1/1: grounded_emotions   , N=2 | Loss 1.3845E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.9347E+00\n",
      "\tInner 1 | Loss 3.4447E+00\n",
      "\tInner 2 | Loss 2.2663E+00\n",
      "\tInner 3 | Loss 9.0311E-01\n",
      "\tInner 4 | Loss 1.4571E+00\n",
      "\tInner 5 | Loss 4.1483E-01\n",
      "\tInner 6 | Loss 4.1660E-01\n",
      "Episode 229 | Task 1/1: grounded_emotions   , N=2 | Loss 1.6393E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.3057E+00\n",
      "\tInner 1 | Loss 1.3738E+00\n",
      "\tInner 2 | Loss 1.7331E+00\n",
      "\tInner 3 | Loss 2.0655E+00\n",
      "\tInner 4 | Loss 2.2695E+00\n",
      "\tInner 5 | Loss 5.8015E-01\n",
      "\tInner 6 | Loss 6.4903E-01\n",
      "Episode 230 | Task 1/1: grounded_emotions   , N=2 | Loss 6.1033E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.4320E+00\n",
      "\tInner 1 | Loss 9.2007E-01\n",
      "\tInner 2 | Loss 1.2907E+00\n",
      "\tInner 3 | Loss 1.0613E+00\n",
      "\tInner 4 | Loss 1.0618E+00\n",
      "\tInner 5 | Loss 6.8476E-01\n",
      "\tInner 6 | Loss 6.3026E-01\n",
      "Episode 231 | Task 1/1: grounded_emotions   , N=2 | Loss 1.2917E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.2655E+00\n",
      "\tInner 1 | Loss 1.0417E+00\n",
      "\tInner 2 | Loss 8.6267E-01\n",
      "\tInner 3 | Loss 6.1413E-01\n",
      "\tInner 4 | Loss 5.9907E-01\n",
      "\tInner 5 | Loss 5.2080E-01\n",
      "\tInner 6 | Loss 4.3989E-01\n",
      "Episode 232 | Task 1/1: grounded_emotions   , N=2 | Loss 3.0219E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.8842E+00\n",
      "\tInner 1 | Loss 5.7071E+00\n",
      "\tInner 2 | Loss 1.1946E+00\n",
      "\tInner 3 | Loss 1.0480E+00\n",
      "\tInner 4 | Loss 5.0485E-01\n",
      "\tInner 5 | Loss 6.3186E-01\n",
      "\tInner 6 | Loss 4.8643E-01\n",
      "Episode 233 | Task 1/1: grounded_emotions   , N=2 | Loss 3.0444E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 8.5383E-01\n",
      "\tInner 1 | Loss 7.9038E-01\n",
      "\tInner 2 | Loss 7.4234E-01\n",
      "\tInner 3 | Loss 7.0447E-01\n",
      "\tInner 4 | Loss 6.7185E-01\n",
      "\tInner 5 | Loss 6.3644E-01\n",
      "\tInner 6 | Loss 5.9515E-01\n",
      "Episode 234 | Task 1/1: grounded_emotions   , N=2 | Loss 1.4055E-01, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.0817E+00\n",
      "\tInner 1 | Loss 7.0102E+00\n",
      "\tInner 2 | Loss 1.8449E+00\n",
      "\tInner 3 | Loss 3.6241E+00\n",
      "\tInner 4 | Loss 6.2282E-01\n",
      "\tInner 5 | Loss 5.4182E-01\n",
      "\tInner 6 | Loss 2.9169E-01\n",
      "Episode 235 | Task 1/1: grounded_emotions   , N=2 | Loss 6.7730E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.2760E+00\n",
      "\tInner 1 | Loss 6.0749E+00\n",
      "\tInner 2 | Loss 9.2006E+00\n",
      "\tInner 3 | Loss 6.2175E+00\n",
      "\tInner 4 | Loss 1.7933E+00\n",
      "\tInner 5 | Loss 7.1256E-01\n",
      "\tInner 6 | Loss 4.3919E-01\n",
      "Episode 236 | Task 1/1: grounded_emotions   , N=2 | Loss 2.0505E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.9676E+00\n",
      "\tInner 1 | Loss 6.2530E-01\n",
      "\tInner 2 | Loss 2.6596E+00\n",
      "\tInner 3 | Loss 5.1574E+00\n",
      "\tInner 4 | Loss 1.9213E-01\n",
      "\tInner 5 | Loss 1.4243E-01\n",
      "\tInner 6 | Loss 4.0743E-02\n",
      "Episode 237 | Task 1/1: grounded_emotions   , N=2 | Loss 4.6141E-04, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.1086E+00\n",
      "\tInner 1 | Loss 2.3035E+00\n",
      "\tInner 2 | Loss 5.0564E+00\n",
      "\tInner 3 | Loss 1.2177E+00\n",
      "\tInner 4 | Loss 7.2864E-01\n",
      "\tInner 5 | Loss 5.2710E-01\n",
      "\tInner 6 | Loss 3.9141E-01\n",
      "Episode 238 | Task 1/1: grounded_emotions   , N=2 | Loss 2.3915E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.5453E+00\n",
      "\tInner 1 | Loss 1.2617E+00\n",
      "\tInner 2 | Loss 3.4047E+00\n",
      "\tInner 3 | Loss 8.8231E-01\n",
      "\tInner 4 | Loss 5.2517E-01\n",
      "\tInner 5 | Loss 2.7909E-01\n",
      "\tInner 6 | Loss 1.9608E-01\n",
      "Episode 239 | Task 1/1: grounded_emotions   , N=2 | Loss 6.3619E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.0636E+00\n",
      "\tInner 1 | Loss 1.1147E+00\n",
      "\tInner 2 | Loss 2.1707E+00\n",
      "\tInner 3 | Loss 3.6997E+00\n",
      "\tInner 4 | Loss 4.3543E-01\n",
      "\tInner 5 | Loss 3.1566E-01\n",
      "\tInner 6 | Loss 2.3459E-01\n",
      "Episode 240 | Task 1/1: grounded_emotions   , N=2 | Loss 3.3819E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.1165E+00\n",
      "\tInner 1 | Loss 2.2677E+00\n",
      "\tInner 2 | Loss 3.5234E+00\n",
      "\tInner 3 | Loss 1.8110E+00\n",
      "\tInner 4 | Loss 8.3339E-01\n",
      "\tInner 5 | Loss 6.7914E-01\n",
      "\tInner 6 | Loss 5.7791E-01\n",
      "Episode 241 | Task 1/1: grounded_emotions   , N=2 | Loss 7.9089E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 2.2676E+00\n",
      "\tInner 1 | Loss 1.9387E+00\n",
      "\tInner 2 | Loss 5.5580E+00\n",
      "\tInner 3 | Loss 7.6600E-01\n",
      "\tInner 4 | Loss 6.3260E-01\n",
      "\tInner 5 | Loss 5.8509E-01\n",
      "\tInner 6 | Loss 5.4160E-01\n",
      "Episode 242 | Task 1/1: grounded_emotions   , N=2 | Loss 4.8582E-01, Acc 96.88, F1 96.87\n",
      "\tInner 0 | Loss 2.2845E+00\n",
      "\tInner 1 | Loss 1.6296E+00\n",
      "\tInner 2 | Loss 9.6247E-01\n",
      "\tInner 3 | Loss 4.2136E-01\n",
      "\tInner 4 | Loss 3.3966E-01\n",
      "\tInner 5 | Loss 1.9742E+00\n",
      "\tInner 6 | Loss 4.2970E+00\n",
      "Episode 243 | Task 1/1: grounded_emotions   , N=2 | Loss 7.9449E-01, Acc 65.62, F1 61.02\n",
      "\tInner 0 | Loss 9.9182E-01\n",
      "\tInner 1 | Loss 1.5587E+00\n",
      "\tInner 2 | Loss 4.4304E+00\n",
      "\tInner 3 | Loss 2.8145E+00\n",
      "\tInner 4 | Loss 6.2762E-01\n",
      "\tInner 5 | Loss 5.3038E-01\n",
      "\tInner 6 | Loss 4.5502E-01\n",
      "Episode 244 | Task 1/1: grounded_emotions   , N=2 | Loss 8.1993E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.7584E+00\n",
      "\tInner 1 | Loss 1.6996E+00\n",
      "\tInner 2 | Loss 1.4671E+00\n",
      "\tInner 3 | Loss 7.6761E-01\n",
      "\tInner 4 | Loss 5.0844E-01\n",
      "\tInner 5 | Loss 3.1172E-01\n",
      "\tInner 6 | Loss 1.9741E-01\n",
      "Episode 245 | Task 1/1: grounded_emotions   , N=2 | Loss 1.3265E-03, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.0917E+00\n",
      "\tInner 1 | Loss 9.0300E-01\n",
      "\tInner 2 | Loss 6.0915E-01\n",
      "\tInner 3 | Loss 4.2353E-01\n",
      "\tInner 4 | Loss 4.6265E-01\n",
      "\tInner 5 | Loss 9.5254E-01\n",
      "\tInner 6 | Loss 4.5482E-01\n",
      "Episode 246 | Task 1/1: grounded_emotions   , N=2 | Loss 1.8185E-02, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 1.4855E+00\n",
      "\tInner 1 | Loss 8.1099E-01\n",
      "\tInner 2 | Loss 2.8536E-01\n",
      "\tInner 3 | Loss 1.1278E-01\n",
      "\tInner 4 | Loss 1.3318E-01\n",
      "\tInner 5 | Loss 1.4649E-01\n",
      "\tInner 6 | Loss 6.8068E-01\n",
      "Episode 247 | Task 1/1: grounded_emotions   , N=2 | Loss 2.6376E+00, Acc 56.25, F1 45.89\n",
      "\tInner 0 | Loss 6.3054E-01\n",
      "\tInner 1 | Loss 5.8910E-01\n",
      "\tInner 2 | Loss 5.6788E-01\n",
      "\tInner 3 | Loss 5.4759E-01\n",
      "\tInner 4 | Loss 5.2031E-01\n",
      "\tInner 5 | Loss 5.0026E-01\n",
      "\tInner 6 | Loss 4.7730E-01\n",
      "Episode 248 | Task 1/1: grounded_emotions   , N=2 | Loss 2.4326E-01, Acc 100.00, F1 100.00\n",
      "\tInner 0 | Loss 6.7942E-01\n",
      "\tInner 1 | Loss 5.2471E-01\n",
      "\tInner 2 | Loss 5.0087E-01\n",
      "\tInner 3 | Loss 4.7968E-01\n",
      "\tInner 4 | Loss 4.6038E-01\n",
      "\tInner 5 | Loss 4.4129E-01\n",
      "\tInner 6 | Loss 4.2513E-01\n",
      "Episode 249 | Task 1/1: grounded_emotions   , N=2 | Loss 1.6941E-01, Acc 100.00, F1 100.00\n"
     ]
    }
   ],
   "source": [
    "source_name = dataset_sampler(dataset, sampling_method='sqrt')\n",
    "_, query_loader = dataset.get_dataloader(source_name, k=k, tokenizer=tokenizer, shuffle=True)\n",
    "query_batch = next(query_loader)\n",
    "q_labels, q_text, q_attn_mask = query_batch\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "    for ii in range(n_outer):\n",
    "\n",
    "        source_name = dataset_sampler(dataset, sampling_method='sqrt')\n",
    "        support_loader, query_loader = dataset.get_dataloader(source_name, k=k, tokenizer=tokenizer, shuffle=True)\n",
    "\n",
    "        # Inner loop\n",
    "        # Support set\n",
    "        batch = next(query_loader)\n",
    "        labels, text, attn_mask = batch\n",
    "\n",
    "        #model.train()\n",
    "        model.eval()\n",
    "        model.adapt(labels, text, attn_mask, task_name=source_name, verbose=True)\n",
    "\n",
    "        # Outer loop\n",
    "        # Query set\n",
    "        query_batch = next(query_loader)\n",
    "        q_labels, q_text, q_attn_mask = query_batch\n",
    "\n",
    "        model.eval()\n",
    "        logits = model(q_text, q_attn_mask)\n",
    "        loss = model.lossfn(logits, q_labels)\n",
    "\n",
    "        model.backward(loss)\n",
    "\n",
    "        # Logging\n",
    "        n_classes = len(dataset.label_map[source_name].keys())\n",
    "        with torch.no_grad():\n",
    "            mets = logging_metrics(logits.detach().cpu(), q_labels.detach().cpu())\n",
    "        print(\"Episode {} | Task {}/{}: {:<20s}, N={} | Loss {:.4E}, Acc {:5.2f}, F1 {:5.2f}\".format(episode, ii+1, \\\n",
    "            n_outer,source_name, n_classes, loss.detach().item(), mets['acc']*100, mets['f1']*100))\n",
    "\n",
    "        shared_optimizer.step()\n",
    "        shared_lr_schedule.step()\n",
    "        shared_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Task grounded_emotions: 0/10 | Loss 7.7724E-01, Acc 66.88, F1 66.34\n",
      "Task grounded_emotions: 1/10 | Loss 6.2712E-01, Acc 64.38, F1 64.09\n",
      "Task grounded_emotions: 2/10 | Loss 7.2218E-01, Acc 60.62, F1 58.37\n",
      "Task grounded_emotions: 3/10 | Loss 6.9894E-01, Acc 64.38, F1 63.07\n",
      "Task grounded_emotions: 4/10 | Loss 5.9582E-01, Acc 67.50, F1 67.05\n",
      "Task grounded_emotions: 5/10 | Loss 5.8342E-01, Acc 70.62, F1 70.38\n",
      "Task grounded_emotions: 6/10 | Loss 6.7413E-01, Acc 66.25, F1 66.04\n",
      "Task grounded_emotions: 7/10 | Loss 6.7213E-01, Acc 66.88, F1 66.77\n",
      "Task grounded_emotions: 8/10 | Loss 5.9813E-01, Acc 72.50, F1 72.30\n",
      "Task grounded_emotions: 9/10 | Loss 5.9930E-01, Acc 68.12, F1 67.95\n",
      "Task grounded_emotions | Loss 6.55E-01  6.15E-02, Acc 66.81  3.16, F1 66.24  3.67\n"
     ]
    }
   ],
   "source": [
    "meta_eval = meta_evaluate(model, dataset, tokenizer, config, k=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Train\n",
    "\n",
    "checkpoint_path = './checkpoints/ProtoMAML/unified_test'\n",
    "\n",
    "# Create the correct directory structure\n",
    "os.makedirs(checkpoint_path, exist_ok=True)\n",
    "os.makedirs(os.join.path(checkpoint_path, 'tensorboard'), exist_ok=True)\n",
    "os.makedirs(os.join.path(checkpoint_path, 'checkpoint'), exist_ok=True)\n",
    "\n",
    "# Start the tensorboard logger\n",
    "writer = SummaryWriter(os.join.path(checkpoint_path, 'tensorboard'))\n",
    "\n",
    "macro_f1 = np.mean(list(meta_eval['f1'].values()))\n",
    "\n",
    "writer.add_scalars('Loss/MetaEval', meta_eval['loss'], i)\n",
    "writer.add_scalars('Accuracy/MetaEval', meta_eval['acc'], i)\n",
    "writer.add_scalars('F1/MetaEval', meta_eval['f1'], i)\n",
    "writer.add_scalar('MacroF1/MetaEval', , i)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "33.50312037229538"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "encoder.model.encoder.layer.11.attention.self.query.weight False\nencoder.model.encoder.layer.11.attention.self.query.bias False\nencoder.model.encoder.layer.11.attention.self.key.weight False\nencoder.model.encoder.layer.11.attention.self.key.bias False\nencoder.model.encoder.layer.11.attention.self.value.weight False\nencoder.model.encoder.layer.11.attention.self.value.bias False\nencoder.model.encoder.layer.11.attention.output.dense.weight False\nencoder.model.encoder.layer.11.attention.output.dense.bias False\nencoder.model.encoder.layer.11.attention.output.LayerNorm.weight False\nencoder.model.encoder.layer.11.attention.output.LayerNorm.bias False\nencoder.model.encoder.layer.11.intermediate.dense.weight False\nencoder.model.encoder.layer.11.intermediate.dense.bias False\nencoder.model.encoder.layer.11.output.dense.weight False\nencoder.model.encoder.layer.11.output.dense.bias False\nencoder.model.encoder.layer.11.output.LayerNorm.weight False\nencoder.model.encoder.layer.11.output.LayerNorm.bias False\nencoder.model.pooler.dense.weight True\nencoder.model.pooler.dense.bias True\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "nu = 10\n",
    "\n",
    "for p in model.model_shared.named_parameters():\n",
    "    transformer_layer = re.search(\"(?:encoder\\.layer\\.)([0-9]+)\", p[0])\n",
    "    if transformer_layer and (int(transformer_layer.group(1)) > nu):\n",
    "        print(p[0], p[1].requires_grad)\n",
    "    elif 'pooler' in p[0]:\n",
    "        print(p[0], p[1].requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "encoder.model.embeddings.word_embeddings.weight False\nencoder.model.embeddings.position_embeddings.weight False\nencoder.model.embeddings.token_type_embeddings.weight False\nencoder.model.embeddings.LayerNorm.weight False\nencoder.model.embeddings.LayerNorm.bias False\nencoder.model.encoder.layer.0.attention.self.query.weight False\nencoder.model.encoder.layer.0.attention.self.query.bias False\nencoder.model.encoder.layer.0.attention.self.key.weight False\nencoder.model.encoder.layer.0.attention.self.key.bias False\nencoder.model.encoder.layer.0.attention.self.value.weight False\nencoder.model.encoder.layer.0.attention.self.value.bias False\nencoder.model.encoder.layer.0.attention.output.dense.weight False\nencoder.model.encoder.layer.0.attention.output.dense.bias False\nencoder.model.encoder.layer.0.attention.output.LayerNorm.weight False\nencoder.model.encoder.layer.0.attention.output.LayerNorm.bias False\nencoder.model.encoder.layer.0.intermediate.dense.weight False\nencoder.model.encoder.layer.0.intermediate.dense.bias False\nencoder.model.encoder.layer.0.output.dense.weight False\nencoder.model.encoder.layer.0.output.dense.bias False\nencoder.model.encoder.layer.0.output.LayerNorm.weight False\nencoder.model.encoder.layer.0.output.LayerNorm.bias False\nencoder.model.encoder.layer.1.attention.self.query.weight False\nencoder.model.encoder.layer.1.attention.self.query.bias False\nencoder.model.encoder.layer.1.attention.self.key.weight False\nencoder.model.encoder.layer.1.attention.self.key.bias False\nencoder.model.encoder.layer.1.attention.self.value.weight False\nencoder.model.encoder.layer.1.attention.self.value.bias False\nencoder.model.encoder.layer.1.attention.output.dense.weight False\nencoder.model.encoder.layer.1.attention.output.dense.bias False\nencoder.model.encoder.layer.1.attention.output.LayerNorm.weight False\nencoder.model.encoder.layer.1.attention.output.LayerNorm.bias False\nencoder.model.encoder.layer.1.intermediate.dense.weight False\nencoder.model.encoder.layer.1.intermediate.dense.bias False\nencoder.model.encoder.layer.1.output.dense.weight False\nencoder.model.encoder.layer.1.output.dense.bias False\nencoder.model.encoder.layer.1.output.LayerNorm.weight False\nencoder.model.encoder.layer.1.output.LayerNorm.bias False\nencoder.model.encoder.layer.2.attention.self.query.weight False\nencoder.model.encoder.layer.2.attention.self.query.bias False\nencoder.model.encoder.layer.2.attention.self.key.weight False\nencoder.model.encoder.layer.2.attention.self.key.bias False\nencoder.model.encoder.layer.2.attention.self.value.weight False\nencoder.model.encoder.layer.2.attention.self.value.bias False\nencoder.model.encoder.layer.2.attention.output.dense.weight False\nencoder.model.encoder.layer.2.attention.output.dense.bias False\nencoder.model.encoder.layer.2.attention.output.LayerNorm.weight False\nencoder.model.encoder.layer.2.attention.output.LayerNorm.bias False\nencoder.model.encoder.layer.2.intermediate.dense.weight False\nencoder.model.encoder.layer.2.intermediate.dense.bias False\nencoder.model.encoder.layer.2.output.dense.weight False\nencoder.model.encoder.layer.2.output.dense.bias False\nencoder.model.encoder.layer.2.output.LayerNorm.weight False\nencoder.model.encoder.layer.2.output.LayerNorm.bias False\nencoder.model.encoder.layer.3.attention.self.query.weight False\nencoder.model.encoder.layer.3.attention.self.query.bias False\nencoder.model.encoder.layer.3.attention.self.key.weight False\nencoder.model.encoder.layer.3.attention.self.key.bias False\nencoder.model.encoder.layer.3.attention.self.value.weight False\nencoder.model.encoder.layer.3.attention.self.value.bias False\nencoder.model.encoder.layer.3.attention.output.dense.weight False\nencoder.model.encoder.layer.3.attention.output.dense.bias False\nencoder.model.encoder.layer.3.attention.output.LayerNorm.weight False\nencoder.model.encoder.layer.3.attention.output.LayerNorm.bias False\nencoder.model.encoder.layer.3.intermediate.dense.weight False\nencoder.model.encoder.layer.3.intermediate.dense.bias False\nencoder.model.encoder.layer.3.output.dense.weight False\nencoder.model.encoder.layer.3.output.dense.bias False\nencoder.model.encoder.layer.3.output.LayerNorm.weight False\nencoder.model.encoder.layer.3.output.LayerNorm.bias False\nencoder.model.encoder.layer.4.attention.self.query.weight False\nencoder.model.encoder.layer.4.attention.self.query.bias False\nencoder.model.encoder.layer.4.attention.self.key.weight False\nencoder.model.encoder.layer.4.attention.self.key.bias False\nencoder.model.encoder.layer.4.attention.self.value.weight False\nencoder.model.encoder.layer.4.attention.self.value.bias False\nencoder.model.encoder.layer.4.attention.output.dense.weight False\nencoder.model.encoder.layer.4.attention.output.dense.bias False\nencoder.model.encoder.layer.4.attention.output.LayerNorm.weight False\nencoder.model.encoder.layer.4.attention.output.LayerNorm.bias False\nencoder.model.encoder.layer.4.intermediate.dense.weight False\nencoder.model.encoder.layer.4.intermediate.dense.bias False\nencoder.model.encoder.layer.4.output.dense.weight False\nencoder.model.encoder.layer.4.output.dense.bias False\nencoder.model.encoder.layer.4.output.LayerNorm.weight False\nencoder.model.encoder.layer.4.output.LayerNorm.bias False\nencoder.model.encoder.layer.5.attention.self.query.weight False\nencoder.model.encoder.layer.5.attention.self.query.bias False\nencoder.model.encoder.layer.5.attention.self.key.weight False\nencoder.model.encoder.layer.5.attention.self.key.bias False\nencoder.model.encoder.layer.5.attention.self.value.weight False\nencoder.model.encoder.layer.5.attention.self.value.bias False\nencoder.model.encoder.layer.5.attention.output.dense.weight False\nencoder.model.encoder.layer.5.attention.output.dense.bias False\nencoder.model.encoder.layer.5.attention.output.LayerNorm.weight False\nencoder.model.encoder.layer.5.attention.output.LayerNorm.bias False\nencoder.model.encoder.layer.5.intermediate.dense.weight False\nencoder.model.encoder.layer.5.intermediate.dense.bias False\nencoder.model.encoder.layer.5.output.dense.weight False\nencoder.model.encoder.layer.5.output.dense.bias False\nencoder.model.encoder.layer.5.output.LayerNorm.weight False\nencoder.model.encoder.layer.5.output.LayerNorm.bias False\nencoder.model.encoder.layer.6.attention.self.query.weight True\nencoder.model.encoder.layer.6.attention.self.query.bias True\nencoder.model.encoder.layer.6.attention.self.key.weight True\nencoder.model.encoder.layer.6.attention.self.key.bias True\nencoder.model.encoder.layer.6.attention.self.value.weight True\nencoder.model.encoder.layer.6.attention.self.value.bias True\nencoder.model.encoder.layer.6.attention.output.dense.weight True\nencoder.model.encoder.layer.6.attention.output.dense.bias True\nencoder.model.encoder.layer.6.attention.output.LayerNorm.weight True\nencoder.model.encoder.layer.6.attention.output.LayerNorm.bias True\nencoder.model.encoder.layer.6.intermediate.dense.weight True\nencoder.model.encoder.layer.6.intermediate.dense.bias True\nencoder.model.encoder.layer.6.output.dense.weight True\nencoder.model.encoder.layer.6.output.dense.bias True\nencoder.model.encoder.layer.6.output.LayerNorm.weight True\nencoder.model.encoder.layer.6.output.LayerNorm.bias True\nencoder.model.encoder.layer.7.attention.self.query.weight True\nencoder.model.encoder.layer.7.attention.self.query.bias True\nencoder.model.encoder.layer.7.attention.self.key.weight True\nencoder.model.encoder.layer.7.attention.self.key.bias True\nencoder.model.encoder.layer.7.attention.self.value.weight True\nencoder.model.encoder.layer.7.attention.self.value.bias True\nencoder.model.encoder.layer.7.attention.output.dense.weight True\nencoder.model.encoder.layer.7.attention.output.dense.bias True\nencoder.model.encoder.layer.7.attention.output.LayerNorm.weight True\nencoder.model.encoder.layer.7.attention.output.LayerNorm.bias True\nencoder.model.encoder.layer.7.intermediate.dense.weight True\nencoder.model.encoder.layer.7.intermediate.dense.bias True\nencoder.model.encoder.layer.7.output.dense.weight True\nencoder.model.encoder.layer.7.output.dense.bias True\nencoder.model.encoder.layer.7.output.LayerNorm.weight True\nencoder.model.encoder.layer.7.output.LayerNorm.bias True\nencoder.model.encoder.layer.8.attention.self.query.weight True\nencoder.model.encoder.layer.8.attention.self.query.bias True\nencoder.model.encoder.layer.8.attention.self.key.weight True\nencoder.model.encoder.layer.8.attention.self.key.bias True\nencoder.model.encoder.layer.8.attention.self.value.weight True\nencoder.model.encoder.layer.8.attention.self.value.bias True\nencoder.model.encoder.layer.8.attention.output.dense.weight True\nencoder.model.encoder.layer.8.attention.output.dense.bias True\nencoder.model.encoder.layer.8.attention.output.LayerNorm.weight True\nencoder.model.encoder.layer.8.attention.output.LayerNorm.bias True\nencoder.model.encoder.layer.8.intermediate.dense.weight True\nencoder.model.encoder.layer.8.intermediate.dense.bias True\nencoder.model.encoder.layer.8.output.dense.weight True\nencoder.model.encoder.layer.8.output.dense.bias True\nencoder.model.encoder.layer.8.output.LayerNorm.weight True\nencoder.model.encoder.layer.8.output.LayerNorm.bias True\nencoder.model.encoder.layer.9.attention.self.query.weight True\nencoder.model.encoder.layer.9.attention.self.query.bias True\nencoder.model.encoder.layer.9.attention.self.key.weight True\nencoder.model.encoder.layer.9.attention.self.key.bias True\nencoder.model.encoder.layer.9.attention.self.value.weight True\nencoder.model.encoder.layer.9.attention.self.value.bias True\nencoder.model.encoder.layer.9.attention.output.dense.weight True\nencoder.model.encoder.layer.9.attention.output.dense.bias True\nencoder.model.encoder.layer.9.attention.output.LayerNorm.weight True\nencoder.model.encoder.layer.9.attention.output.LayerNorm.bias True\nencoder.model.encoder.layer.9.intermediate.dense.weight True\nencoder.model.encoder.layer.9.intermediate.dense.bias True\nencoder.model.encoder.layer.9.output.dense.weight True\nencoder.model.encoder.layer.9.output.dense.bias True\nencoder.model.encoder.layer.9.output.LayerNorm.weight True\nencoder.model.encoder.layer.9.output.LayerNorm.bias True\nencoder.model.encoder.layer.10.attention.self.query.weight True\nencoder.model.encoder.layer.10.attention.self.query.bias True\nencoder.model.encoder.layer.10.attention.self.key.weight True\nencoder.model.encoder.layer.10.attention.self.key.bias True\nencoder.model.encoder.layer.10.attention.self.value.weight True\nencoder.model.encoder.layer.10.attention.self.value.bias True\nencoder.model.encoder.layer.10.attention.output.dense.weight True\nencoder.model.encoder.layer.10.attention.output.dense.bias True\nencoder.model.encoder.layer.10.attention.output.LayerNorm.weight True\nencoder.model.encoder.layer.10.attention.output.LayerNorm.bias True\nencoder.model.encoder.layer.10.intermediate.dense.weight True\nencoder.model.encoder.layer.10.intermediate.dense.bias True\nencoder.model.encoder.layer.10.output.dense.weight True\nencoder.model.encoder.layer.10.output.dense.bias True\nencoder.model.encoder.layer.10.output.LayerNorm.weight True\nencoder.model.encoder.layer.10.output.LayerNorm.bias True\nencoder.model.encoder.layer.11.attention.self.query.weight True\nencoder.model.encoder.layer.11.attention.self.query.bias True\nencoder.model.encoder.layer.11.attention.self.key.weight True\nencoder.model.encoder.layer.11.attention.self.key.bias True\nencoder.model.encoder.layer.11.attention.self.value.weight True\nencoder.model.encoder.layer.11.attention.self.value.bias True\nencoder.model.encoder.layer.11.attention.output.dense.weight True\nencoder.model.encoder.layer.11.attention.output.dense.bias True\nencoder.model.encoder.layer.11.attention.output.LayerNorm.weight True\nencoder.model.encoder.layer.11.attention.output.LayerNorm.bias True\nencoder.model.encoder.layer.11.intermediate.dense.weight True\nencoder.model.encoder.layer.11.intermediate.dense.bias True\nencoder.model.encoder.layer.11.output.dense.weight True\nencoder.model.encoder.layer.11.output.dense.bias True\nencoder.model.encoder.layer.11.output.LayerNorm.weight True\nencoder.model.encoder.layer.11.output.LayerNorm.bias True\nencoder.model.pooler.dense.weight True\nencoder.model.pooler.dense.bias True\nmlp.mlp.0.weight True\nmlp.mlp.0.bias True\nmlp.mlp.2.weight True\nmlp.mlp.2.bias True\n"
     ]
    }
   ],
   "source": [
    "for p in model.model_shared.named_parameters():\n",
    "    print(p[0], p[1].requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "protomaml_model = ProtoMAMLSeqTransformer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = protomaml_model(text, attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[tensor([-0.0880, -0.0837, -0.0354,  0.0504, -0.0133, -0.0463,  0.0563,  0.0804,\n",
       "         -0.0108, -0.0040,  0.1059,  0.0320, -0.0608, -0.0685, -0.0003,  0.0337,\n",
       "          0.0723,  0.0244, -0.0407,  0.0020, -0.0197,  0.0062, -0.0267, -0.0110,\n",
       "          0.0636, -0.0142, -0.0067, -0.0275, -0.0701,  0.0087,  0.0288,  0.0049,\n",
       "          0.0486, -0.0030,  0.0411, -0.0301, -0.0305, -0.0353, -0.0668, -0.0309,\n",
       "         -0.0090,  0.0304,  0.0208, -0.0100, -0.0608,  0.0575, -0.0426,  0.0170,\n",
       "         -0.0272,  0.0239,  0.0743, -0.0018, -0.0092,  0.0623,  0.0986,  0.0686,\n",
       "         -0.0170, -0.0061, -0.0131,  0.0352,  0.0503, -0.0456,  0.0461, -0.0134,\n",
       "          0.0292,  0.0660,  0.0106,  0.0080,  0.0227, -0.0028,  0.0255, -0.0472,\n",
       "          0.0935,  0.0673, -0.1418,  0.0963,  0.0099,  0.0062,  0.0724,  0.0183,\n",
       "          0.0222, -0.1021, -0.0392,  0.0616,  0.0392,  0.0497, -0.0222,  0.0508,\n",
       "         -0.0213, -0.0316, -0.0310, -0.0713,  0.0098, -0.0403,  0.0167, -0.0409,\n",
       "          0.0767, -0.0660,  0.0368, -0.0585,  0.0273, -0.0389,  0.0058, -0.0406,\n",
       "         -0.0748, -0.0613, -0.0615,  0.0632,  0.0070,  0.0204, -0.0140, -0.0293,\n",
       "          0.0109,  0.1069, -0.0161, -0.1158,  0.0433, -0.0226,  0.0422, -0.0823,\n",
       "         -0.0313, -0.1169,  0.0006,  0.0547,  0.0415, -0.0998,  0.0631, -0.0404],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0910, -0.0782, -0.0358,  0.0513, -0.0156, -0.0391,  0.0594,  0.0798,\n",
       "         -0.0101, -0.0016,  0.1042,  0.0315, -0.0617, -0.0661, -0.0004,  0.0323,\n",
       "          0.0721,  0.0260, -0.0379, -0.0053, -0.0129,  0.0063, -0.0268, -0.0102,\n",
       "          0.0656, -0.0155, -0.0056, -0.0258, -0.0744,  0.0061,  0.0288,  0.0052,\n",
       "          0.0459, -0.0034,  0.0381, -0.0331, -0.0326, -0.0400, -0.0638, -0.0352,\n",
       "         -0.0070,  0.0340,  0.0215, -0.0125, -0.0643,  0.0549, -0.0391,  0.0145,\n",
       "         -0.0253,  0.0280,  0.0709, -0.0039, -0.0066,  0.0571,  0.0997,  0.0653,\n",
       "         -0.0178, -0.0037, -0.0142,  0.0402,  0.0519, -0.0423,  0.0457, -0.0154,\n",
       "          0.0331,  0.0637,  0.0136,  0.0004,  0.0264,  0.0006,  0.0241, -0.0440,\n",
       "          0.0926,  0.0672, -0.1459,  0.0980,  0.0106,  0.0041,  0.0748,  0.0178,\n",
       "          0.0197, -0.0993, -0.0403,  0.0632,  0.0373,  0.0522, -0.0202,  0.0435,\n",
       "         -0.0204, -0.0308, -0.0315, -0.0690,  0.0083, -0.0456,  0.0117, -0.0415,\n",
       "          0.0733, -0.0649,  0.0324, -0.0567,  0.0268, -0.0356,  0.0040, -0.0367,\n",
       "         -0.0731, -0.0588, -0.0570,  0.0656,  0.0044,  0.0129, -0.0104, -0.0337,\n",
       "          0.0153,  0.1068, -0.0170, -0.1128,  0.0437, -0.0235,  0.0423, -0.0819,\n",
       "         -0.0321, -0.1175,  0.0012,  0.0568,  0.0398, -0.1052,  0.0626, -0.0411],\n",
       "        grad_fn=<MeanBackward1>)]"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "[torch.mean(y[labels == i], dim=0) for i in dataset.label_map[source_name].values()]"
   ]
  }
 ]
}