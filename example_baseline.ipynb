{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in packages\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from models.transformer_clf import Transformer_CLF\n",
    "from data.meta_dataset import MetaDataset\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'include':['go_emotions'],\n",
    "         'encoder_name':'bert-base-uncased',\n",
    "         'nu':-1,\n",
    "         'hidden_dims':[256, 128],\n",
    "         'act_fn':'Tanh',\n",
    "         'lr':1e-5,\n",
    "         'batch_size':8,\n",
    "         'max_epochs':1,\n",
    "         'version':'go_emotions_test',\n",
    "         'checkpoint_path':'./checkpoints/baselines',\n",
    "         'gpu': True}\n",
    "\n",
    "device = 'cuda' if (torch.cuda.is_available() and config['gpu']) else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, device, cutoff=100):\n",
    "        self.samples = []\n",
    "        \n",
    "        for label in sorted(dataset.keys()):\n",
    "            for i, point in enumerate(dataset[label]):\n",
    "                tokenized_input = tokenizer(point['text'],\n",
    "                                    return_tensors='pt',\n",
    "                                    padding='max_length',\n",
    "                                    truncation=True).to(device)\n",
    "\n",
    "                self.samples.append((tokenized_input['input_ids'].squeeze(), tokenized_input['attention_mask'].squeeze(),\n",
    "                          label))\n",
    "            #if i > cutoff:\n",
    "                #break\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataloaders(dataset, tokenizer, device, batch_size=8, extract='go_emotions', shuffle=True, num_workers=0):\n",
    "    data_splits = {}\n",
    "    for split in dataset[extract].keys():\n",
    "        data_split = CustomDataset(dataset[extract][split], tokenizer, device)\n",
    "        data_split_loader = torch.utils.data.DataLoader(data_split, shuffle=shuffle, batch_size=batch_size, num_workers=num_workers)\n",
    "        data_splits[split] = data_split_loader\n",
    "        \n",
    "    return data_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLFTrainer(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # Exports the hyperparameters to a YAML file, and create \"self.hparams\" namespace\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.config = config\n",
    "        # Create model        \n",
    "        self.model = Transformer_CLF(config)\n",
    "        # # Create loss module\n",
    "        self.loss_module = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    def forward(self, text, attn_mask):\n",
    "        return self.model(text, attn_mask)\n",
    "\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.SGD(self.parameters(), self.config[\"lr\"])\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.99)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "\n",
    "    def encode(self, text, attn_mask=None):\n",
    "        return self.model.encode(text, attn_mask)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # \"batch\" is the output of the train data loader.\n",
    "        text, attn_mask, labels = batch\n",
    "        preds = self.model(text, attn_mask)\n",
    "        loss = self.loss_module(preds, labels)\n",
    "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
    "        \n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True) # Logs the accuracy per epoch to tensorboard (weighted average over batches)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss # Return tensor to call \".backward\" on\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        text, attn_mask, labels = batch\n",
    "        \n",
    "        preds = self.model(text, attn_mask).argmax(dim=-1)\n",
    "        acc = (labels == preds).float().mean()\n",
    "\n",
    "        self.log('val_acc', acc) # By default logs it per epoch (weighted average over batches)\n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        text, attn_mask, labels = batch\n",
    "        preds = self.model(text, attn_mask).argmax(dim=-1)\n",
    "        acc = (labels == preds).float().mean()\n",
    "        self.log('test_acc', acc) # By default logs it per epoch (weighted average over batches), and returns it afterwards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: go_emotions/simplified\n",
      "Reusing dataset go_emotions (C:\\Users\\luuk1\\.cache\\huggingface\\datasets\\go_emotions\\simplified\\0.0.0\\b781b3f96f1b333b895ded30861c0d4a07d66e1cfbdfb89bc3fb4d5fc899aa27)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65423d9e0f004d5b90dd4a470f9e5dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=44.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc73b516c77643ebac29fb06153253fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6501117ff0f84a36b0cb8bff6bfa00c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "creating dataloaders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Global seed set to 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating trainer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | model       | Transformer_CLF  | 109 M \n",
      "1 | loss_module | CrossEntropyLoss | 0     \n",
      "-------------------------------------------------\n",
      "85.9 M    Trainable params\n",
      "23.8 M    Non-trainable params\n",
      "109 M     Total params\n",
      "438.862   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luuk1\\miniconda3\\envs\\atcs\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\users\\luuk1\\miniconda3\\envs\\atcs\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Global seed set to 1234\n",
      "c:\\users\\luuk1\\miniconda3\\envs\\atcs\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc0042494e843a0a5cb709ca6b55c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbf67a0dbf24e58b2a1987e424d2870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "import torch.nn as nn\n",
    "\n",
    "def train_model(config):\n",
    "    \"\"\"\n",
    "    Function for training and testing a NLI model.\n",
    "    Inputs:\n",
    "        config - Namespace object from the argument parser\n",
    "    \"\"\"\n",
    "    \n",
    "    device = 'cuda' if (torch.cuda.is_available() and config['gpu']) else 'cpu'\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config['encoder_name'])\n",
    "    \n",
    "    print(\"Extracting datasets\")\n",
    "    # ToDo: process data and make sure it uses same amount of training data as protomaml\n",
    "    dataset = MetaDataset(include=config['include'])\n",
    "    tokenizer_kwargs = {'return_tensors':'pt',\n",
    "                                    'padding':'max_length',\n",
    "                                    'truncation':True}\n",
    "    \n",
    "    dataset.prep(tokenizer)\n",
    "    \n",
    "    print(\"creating dataloaders\")\n",
    "    data_loaders = extract_dataloaders(dataset, tokenizer, device, config['batch_size'])\n",
    "    train_loader = data_loaders['train']\n",
    "    validation_loader = data_loaders['validation']\n",
    "    test_loader = data_loaders['test']\n",
    "    \n",
    "    # ToDo: add n_classes\n",
    "    config[\"n_classes\"] = 27\n",
    "\n",
    "    print('creating trainer')\n",
    "    checkpoint_callback = ModelCheckpoint(dirpath=config['checkpoint_path'], save_weights_only=True, mode=\"max\", monitor=\"val_acc\")\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join(config['checkpoint_path'], config['version']),                                \n",
    "                         checkpoint_callback=checkpoint_callback, \n",
    "                         gpus=1 if str(device)==\"cuda\" else 0,                                                     \n",
    "                         max_epochs=config['max_epochs'],                                                                           \n",
    "                         progress_bar_refresh_rate=1\n",
    "                         )                                                                  \n",
    "    trainer.logger._log_graph = False      \n",
    "    trainer.logger._default_hp_metric = None\n",
    "\n",
    "    pl.seed_everything(1234) \n",
    "    \n",
    "    model = CLFTrainer(config)\n",
    "    trainer.fit(model, train_loader, validation_loader)\n",
    "    \n",
    "    model = CLFTrainer.load_from_checkpoint(checkpoint_callback.best_model_path)\n",
    "    test_result = trainer.test(model, test_dataloaders=test_loader, verbose=False)\n",
    "    \n",
    "    return model\n",
    "\n",
    "train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "bdd9dddc0c2a62cdbffe4f517a5aef7a5b5eb43447af9d9dff6ca93694c50ea2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
